namespace: swh
environment: production

sentry:
  environment: production

# List of kafka brokers
# used by storage to store the object inserted in the database
# and by the journal clients to follow the storage activiiy
# kafkaBrokers:
#   - myBroker1
#   - myBroker2

# Typical storage's journal writer configuration
# journalWriterConfiguration:
#   kafkaBrokersRef: kafkaBrokers
#   prefix: swh.journal.objects
#   clientId: swh.storage.journal_writer.storage
#   anonymize: true
#   producerConfig:
#     message.max.bytes: 1000000000

# journalClientConfiguration:
#   kafkaBrokersRef: kafkaBrokers
#   groupId: swh.scheduler.journal_client

# postgresqlStorageConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   user: swh
#   pass: ${POSTGRESQL_PASSWORD}
#   db: swh
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-common-secret
#       secretKeyName: postgres-swh-password

# List of cassandra nodes
# when cassandra is used a backend
# cassandraSeeds:
#   - myCassandraSeeds1
#   - myCassandraSeeds1

# Typical cassandra storage configuration
# cassandraStorageConfiguration:
#   cls: cassandra
#   cassandraSeedsRef: cassandraSeeds
#   keyspace: swh
#   initKeySpace: false
#   consistencyLevel: LOCAL_QUORUM
#   authProvider:
#     cls: cassandra.auth.PlainTextAuthProvider
#     username: swh-rw
#     password: ${CASSANDRA_PASSWORD}
#   specificOptions:
#     directory_entries_insert_algo: batch

# Typical remote storage configuration
# remoteStorageConfiguration:
#   cls: remote
#   host: http://storage:5002

# Typical remote objstorage configuration
# remoteObjstorageConfiguration:
#   cls: remote
#   host: http://objstorage:5003

# searchConfiguration:
#   cls: remote
#   url: http://myswhsearch.localdomain:5010

# djangoWebConfiguration:
#   secrets:
#     DJANGO_SECRET_KEY:
#       secretKeyRef: common-secrets
#       secretKeyName: webapp-django-secret-key

# azureCacheConfiguration:
#   cls: azure
#   account_name: vaultstorageaccount
#   container_name: contents
#   api_secret_key: ${API_SECRET_KEY}
#   secrets:
#     API_SECRET_KEY:
#       secretKeyRef: swh-vault-azure-secret
#       secretKeyName: azure-swh-vault-key

# Example of a storage pipeline configuration
# Adapt according your platform capabilities
# Used by loaders and possibly journal client / replayers
# storageClientPipelineSteps:
#     - cls: buffer
#       min_batch_size:
#         content: 100
#         content_bytes: 52428800
#         directory: 100
#         directory_entries: 500
#         revision: 100
#         revision_parents: 200
#         revision_bytes: 52428800
#         release: 100
#         release_bytes: 52428800
#         extid: 100
#     - cls: filter
#     - cls: retry

# Noop object storage configuration
# noopObjectStorage:
#   cls: noop

# Typical storage configuration
# Use references to other entries to assemble
# a complete storage configuration
# Only storageConfigurationRef is mandatory if a remote
# storage is used.
# objectStorageConfigurationRef is mandatory for all other
# storage types
#
# defaultStorageClientConfiguration:
#   # pipelineStepsRef: storageClientPipelineSteps

#   # exhaustive supported storage types
#   # storageConfigurationRef: remoteStorageConfiguration
#   storageConfigurationRef: cassandraStorageConfiguration
#   # storageConfigurationRef: postgresqlStorageConfiguration

#   # journalWriterConfigurationRef: journalWriterConfiguration
#   # objectStorageConfigurationRef: noopObjectStorage

# defaultStorageConfiguration:
#   storageConfigurationRef: postgresqlStorageConfiguration
#   objectStorageConfiguration: remoteObjectStorageConfiguration

# defaultIndexerStorageConfiguration:
#   cls: postgresql
#   host: indexer-storage.server
#   db: swh-indexer
#   port: 5432
#   user: swh
#   pass: ${POSTGRESQL_PASSWORD}
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-indexer-storage-postgresql-secret
#       secretKeyName: postgres-swh-indexer-password

# globalROStorageConfiguration:
# TODO: define this configuration

# postgresqlWebConfiguration:
#   host: db.internal.softwareheritage.org
#   port: 5432
#   db: swh-web
#   user: swh-web
#   pass: ${POSTGRESQL_PASSWORD}
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-web-secret
#       secretKeyName: postgres-swh-web-password

# postgresqlSchedulerConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   user: swh-scheduler
#   pass: ${POSTGRESQL_PASSWORD}
#   db: swh
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-common-secret
#       secretKeyName: postgres-swh-password

# postgresqlVaultConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   db: swh-vault
#   user: swh-vault
#   password: ${POSTGRESQL_PASSWORD}
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-vault-secret
#       secretKeyName: postgres-swh-vault-password

# remoteSchedulerConfiguration:
#   cls: remote
#   url: http://scheduler.internal.staging.swh.network

# guestCeleryConfiguration:
#   host: scheduler0.internal.staging.swh.network
#   port: 5672
#   user: guest
#   pass: ${AMQP_PASSWORD}
#   secrets:
#     AMQP_PASSWORD:
#       secretKeyRef: amqp-secrets
#       secretKeyName: guest-password

# producerCeleryConfiguration:
#   host: scheduler0.internal.staging.swh.network
#   port: 5672
#   user: swhproducer
#   pass: ${AMQP_PASSWORD}
#   secrets:
#     AMQP_PASSWORD:
#       secretKeyRef: amqp-secrets
#       secretKeyName: swhproducer-password

# consumerCeleryConfiguration:
#   host: scheduler0.internal.staging.swh.network
#   port: 5672
#   user: swhconsumer
#   pass: ${AMQP_PASSWORD}
#   secrets:
#     AMQP_PASSWORD:
#       secretKeyRef: amqp-secrets
#       secretKeyName: swhconsumer-password

# depositConfiguration:
#   host:
#   user: ${DEPOSIT_USERNAME}
#   pass: ${DEPOSIT_PASSWORD}
#   secrets:
#     DEPOSIT_USER:
#       secretKeyRef: deposit-secrets
#       secretKeyName: read-write
#     DEPOSIT_PASSWORD:
#       secretKeyRef: deposit-secrets
#       secretKeyName: read-write

# remoteVaultConfiguration:
#   cls: remote
#   url: http://<vault service url>

# remoteIndexerStorageConfiguration:
#   cls: remote
#   url: http://<indexer storage service url>

# remoteCountersConfiguration
#   cls: remote
#   url: http://<counters service url>

# defaultJournalWriterConfiguration:
#   brokersConfigurationRef: kafkaBrokers
#   clientId: swh.storage.journal_writer.storage1
#   producerConfig: |-
#     message.max.bytes: 1000000000
#     item2: value2
#     item3: value3
#   # optional values with their default value
#   prefix: swh.journal.objects
#   anonymize: true

giveConfiguration:
  public: ${GIVE_PUBLIC_KEY}
  token: ${GIVE_PRIVATE_TOKEN}
  secrets:
    GIVE_PUBLIC_KEY:
      secretKeyRef: web-give-secrets
      secretKeyName: public-key
    GIVE_PRIVATE_TOKEN:
      secretKeyRef: web-give-secrets
      secretKeyName: private-token

graphql:
  enabled: false
  priorityClassName: frontend-rpc
  logLevel: INFO
  debug: no
  introspection: yes
  # requestedMemory: 150Mi
  # requestedCpu: 50m
  # maxQueryCost for anonymous users
  anonymousUserMaxQueryCost: 50
  authenticatedUserMaxQueryCost: 500
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: graphql-sentry-dsn
#    # check defaultStorageConfiguration example to configure your storage
#    storageConfigurationRef: defaultROStorageClientConfiguration
#    searchConfigurationRef: searchConfiguration
#  ingress:
#    enabled: false
#    httpPath: /graphql
#    host: my_host # Optional
  auth:
    enabled: false
    # More information in https://gitlab.softwareheritage.org/swh/devel/swh-auth/-/blob/master/README.rst
    # server: https://auth.backend.url/
    # optional, when not provided, graphql defaults to use "server" entry
    # public_server: https://another.auth.backend.url/
    #realm: MyAuthDomain
    client: swh-web
    # memory:// or memcached://memcached:port
    cacheUrl: memory://
  # maxRawContentSize: 10000

# Allow to specify a specific configuration for pod's /tmp
# directory. Mostly used to configure the loaders to work
# on specific tmpfs on the nodes.
# It can be necessary when using a memory emptyDir is not sufficient
tmpEphemeralStorage:
  claimTemplate: {}
    # ephemeral:
    #   volumeClaimTemplate:
    #     metadata:
    #       labels:
    #         type: ephemeral-volume
    #     spec:
    #       accessModes: [ "ReadWriteOnce" ]
    #       storageClassName: "local-path"
    #       resources:
    #         requests:
    #           storage: 100Gi # no effects
  # workaround because helm merges the map values when overridden
  # It shouldn't have to be modified
  default:
    emptyDir: {}

storage_replayer:
  enabled: false
  priorityClassName: background-workload
  maxMessagesBytes: "524288000"
  journalBrokers:
    # The name of the secret containing the BROKER_USER_PASSWORD value
    # secretName: storage-replayer-broker-secret
    hosts:
    - broker1
    - broker2
    user: myuser
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageReplayerConfiguration
  # optional 'replayer' configuration may be specified with a 'error_reporter' config
  # entry allowing to specify redis connection parameters. It will be used to report
  # non-recoverable replaying issues
  # error_reporter:
  #   host: redis.redis
  #   port: 6379
  #   db: 1

  # When true, check db & code versions and do not start if they diverge
  checkDbVersion: false

  deployments:
  # Example of deployments
  #   origins:
  #     privileged: false
  #     objects:
  #       - origin
  #       - origin_visits
  #       - origin_visits_status
  #     batchSize: 250
  #   revisions:
  #     privileged: false
  #     objects:
  #       - revision
  #     batchSize: 1000
  #     autoScaling:
  #       poolInterval: 120
  #       lagThreashold: 1000
  #       minReplicaCount: 1
  #       maxReplicaCount: 10

loader_metadata:
  enabled: false
  priorityClassName: normal-workload
  sentrySwhPackage: swh.loader.metadata
  requestedMemory: 350Mi
  requestedCpu: 80m
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageClientConfiguration
  # schedulerConfigurationRef: defaultSchedulerConfiguration
  # consumerGroup: ...
  # prefix: swh.journal.objects
  # reload_after_days: 120
  # journalBrokers:
  #   hosts:
  #     - ...
  #   user: ...
  autoScaling:
    enabled: true
  #   poolInterval: 120
  #   lagThreashold: 1000
  #   minReplicaCount: 1
  #   maxReplicaCount: 10

loaders:
  enabled: false
  priorityClassName: normal-workload
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageClientConfiguration
  # celeryConfigurationRef: consumerCeleryConfiguration
  # sysctls:
  #   net.ipv4.tcp_dsack: 0
  deployments:
  # Example of deployments
    # git:
    #   requestedMemory: 256Mi
    #   requestedCpu: 200m
    #   queues:
    #     - swh.loader.git.tasks.UpdateGitRepository
    #   sysctls:
    #     net.ipv4.tcp_dsack: 0
    #   autoScaling:
    #     # Downscale to 0 loaders when the queue is empty
    #     stopWhenNoActivity: false
    #     queueThreshold: 10  # spawn worker per increment of `value` messages
    #     minReplicacount: 1
    #     maxReplicaCount: 3

cookers:
  enabled: false
  priorityClassName: normal-workload
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # celeryConfigurationRef: consumerCeleryConfiguration
  # vaultConfigurationRef: remoteVaultConfiguration

checker_deposit:
  enabled: false
  priorityClassName: frontend-rpc-workload
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # celeryConfigurationRef: consumerCeleryConfiguration
  depositConfigurationRef: depositConfiguration

indexers:
  enabled: false
  priorityClassName: frontend-rpc
  sentrySwhPackage: swh.indexer
  # schedulerConfigurationRef: remoteSchedulerConfiguration
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration

listers:
  enabled: false
  priorityClassName: normal-workload
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # schedulerConfigurationRef: defaultSchedulerConfiguration
  # celeryConfigurationRef: consumerCeleryConfiguration

indexerStorage:
  enabled: false
  priorityClassName: frontend-rpc
  logLevel: INFO
# Don't configure the replicas if autoscaling is configured
# and vice-versa
# replicas: 1
  requestedCpu: 50m
  requestedMemory: 100Mi
# autoScaling:
#   minReplicaCount: 2
#   maxReplicaCount: 10
#   cpuPercentageUsage: 100
#  affinity:
#    nodeAffinity:
#      requiredDuringSchedulingIgnoredDuringExecution:
#        nodeSelectorTerms:
#        - matchExpressions:
#          - key: "swh/rpc"
#            operator: In
#            values:
#            - "true"
#  gunicorn:
#    threads: 5
#    workers: 2
#    timeout: 60
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: indexer-storage-sentry-dsn
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  indexerStorageConfigurationRef: defaultIndexerStorageConfiguration
  journalWriteConfigurationRef: defaultJournalWriterConfiguration
  # When true, check db & code versions and do not start if they diverge
  checkDbVersion: false
  # Deploy an ingress to access the storage
  ingress:
    enabled: false
    # Optional: the ingress classname to use
    # className: nginx
    # mandatory if ingress is enabled
    # the hostname on which the storage must be reachable
    # host: mystorage.localdomain

storage:
  enabled: false
  priorityClassName: frontend-rpc
  logLevel: INFO
# Don't configure the replicas if autoscaling is configured
# and vice-versa
# replicas: 1
  requestedCpu: 50m
  requestedMemory: 100Mi
# autoScaling:
#   minReplicaCount: 2
#   maxReplicaCount: 10
#   cpuPercentageUsage: 100
#  affinity:
#    nodeAffinity:
#      requiredDuringSchedulingIgnoredDuringExecution:
#        nodeSelectorTerms:
#        - matchExpressions:
#          - key: "swh/storage"
#            operator: In
#            values:
#            - "true"
#  gunicorn:
#    threads: 5
#    workers: 2
#    timeout: 60
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: storage-sentry-dsn
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageConfiguration

  # When true, check db & code versions and do not start if they diverge
  checkDbVersion: false

  objstorage:
    cls: noop
  ##  if objstorage configuration doesn't contains passwords or sensitive data
  # objstorageClass: filtered
  # objstorageConfig:
  #   storage_conf:
  #     cls: remote
  #     url: http://storage1.internal.staging.swh.network:5003/
  #   filters_conf:
  #   - type: readonly
  ## if objstorage configuration contains passwords or sensitive data
  ## /!\ the configmap indentation (10) had to be defined in the secret
  # objstorageClass: multiplexer
  # objstorageConfig: ${OBJSTORAGECONFIG}

  # Deploy an ingress to access the storage
  ingress:
    enabled: false
    # Optional: the ingress classname to use
    # className: nginx

    # mandatory if ingress is enabled
    # the hostname on which the storage must be reachable
    # host: mystorage.localdomain

  ## if journal access is required
  ## mandatory values
  #journalWriter:
  #  brokers:
  #    - kafka1
  #    - kafka2
  #    - kafka3
  #  clientId: swh.storage.journal_writer.storage1
  #  producerConfig: |-
  #    message.max.bytes: 1000000000
  #    item2: value2
  #    item3: value3
  ## optional values with their default value
  #  prefix: swh.journal.objects
  #  anonymize: true

# internalNetworkRanges:
#   - xxx.xxx.xxx.xxx/24
#   - yyy.yyy.yyy.yyy/24

# externalNetworkRanges:
#   - zzz.zzz.zzz.zzz/24

# throttlingConfiguration:
#   internalExemptedNetworkRangesRef: internalNetworkRanges
#   externalExemptedNetworkRangesRef: externalNetworkRanges
#   # The memcached url, mandatory
#   cache_uri: memcached:11211
#   # rate limit with some network exception
#   scopes_with_exempted_networks:
#     # Possible other scopes are
#     # - swh_api_origin_visit_latest
#     # - swh_vault_cooking
#     # - swh_save_origin
#     # - swh_raw_object
#     swh_api:
#       limiter_rate:
#         default: 120/h
#     swh_api_origin_search:
#       limiter_rate:
#         default: 120/h
#       exempted_networks:
#         - aaa.aaa.aaa.aaa/24
#   # rate limit without any network exemption
#   scopes:
#     # Possible other scopes are
#     # - swh_save_origin
#     # - swh_raw_object
#     swh_api_origin_visit_latest:
#       limiter_rate:
#         default: 120/h
#     swh_vault_cooking:
#       limiter_rate:
#         default: 120/h

web:
  enabled: false
  migrations:
    enabled: false
  priorityClassName: frontend-rpc
  # debug: false
  logLevel: INFO
  requestedCpu: 50m
  requestedMemory: 100Mi
  # replicas: 1
  # autoScaling:
  #   minReplicaCount: 2
  #   maxReplicaCount: 10
  #   cpuPercentageUsage: 50
  refreshSavecodenowStatus:
    enabled: false
    priorityClassName: frontend-rpc-workload
    logLevel: INFO
    # concurrencyPolicy: Forbid
    # At every minute
    cron: "* * * * *"
#  gunicorn:
#    threads: 5
#    workers: 2
#    timeout: 60
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: web-sentry-dsn
  # host: webapp
  ingress:
    enabled: false
  #   extraAnnotations:
  #     cert-manager.io/cluster-issuer: letsencrypt-production-gandi
  #     kubernetes.io/ingress.class: nginx
  #     kubernetes.io/tls-acme: "true"
  #     nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
  #   tlsEnabled: true
  #   whitelistSourceRange:
  #     - 192.168.100.0/24
    endpoints:
      default:
        paths:
          - path: /
          - path: /static
            port: 80
  #     authenticated:
  #       paths:
  #         - path: /api/1/provenance/
  #         - path: /api/1/entity/
  #         - path: /api/1/content/[^/]+/symbol/
  #       # auth-file with authentication
  #       authentication: swh/ingress-auth
  # searchConfigurationRef: searchConfiguration
  # Configure the scheduler instance used for save code now requests
  # schedulerConfigurationRef: schedulerConfiguration
  # storageConfigurationRef: globalROStorageConfiguration
  # vaultConfigurationRef: remoteVaultConfiguration
  # indexerStorageConfigurationRef: remoteIndexerStorageConfiguration
  # countersConfigurationRef: remoteCountersConfiguration
  # djangoConfigurationRef: djangoWebConfiguration
  # If not specified, this will use a sqlite db which is not performant enough for
  # production use.
  # databaseConfigurationRef: postgresqlWebConfiguration
  # depositConfigurationRef: depositConfiguration
  # giveConfigurationRef: giveConfiguration
  # throttlingConfigurationRef: throttlingConfiguration
  # extraConfig:
  #   instance_name: archive.swh.org
  #   allowed_hosts:
  #   - archive.swh.org
  #   debug: false
  #   history_counters_url: http://elastichost.swh.org:5011/counters_history/history.json
  #   es_workers_index_url: http://elastichost.swh.org:9200/swh_workers-*
  #   keycloak:
  #     server_url: https://auth.swh.org/auth/
  #     realm_name: SWHRealm
  #   search_config:
  #     # swh-indexer-storage or swh-search
  #     metadata_backend: swh-indexer-storage
  #   # max content size in bytes
  #   content_display_max_size: 5242880
  #   swh_extra_django_apps:
  #     - swh.web.add_forge_now
  #     - swh.web.archive_coverage
  #     - swh.web.badges
  #     - swh.web.banners
  #     - swh.web.deposit
  #     - swh.web.inbound_email
  #     - swh.web.jslicenses
  #     - swh.web.mailmap
  #     - swh.web.metrics
  #     - swh.web.save_code_now
  #     - swh.web.save_origin_webhooks
  #     - swh.web.vault
  #   add_forge_now:
  #     email_address: add-forge-now@archive.swh.org
  #   deposit:
  #     private_api_url: "https://deposit-rp.i.s.s.n/1/private/"
  #     private_api_user: "${DEPOSIT_USERNAME}"
  #     private_api_password: "${DEPOSIT_PASSWORD}"
  #   give:
  #     public_key: ${GIVE_PUBLIC_KEY}
  #     token: ${GIVE_PRIVATE_TOKEN}

statsd_exporter:
  enabled: false
  priorityClassName: system
  image: prom/statsd-exporter
  imageVersion: "v0.22.7"

memcached:
  # Deploy a memcached instance used by the webapp and graphql for sessions caching
  enabled: false
  priorityClassName: storages
  image: memcached:1.6.18
  memory: 256m
  requestedCpu: 100m
  requestedMemory: 300Mi
  prometheus:
    # Activate the deployment of the memcached exporter and ServiceMonitor
    enabled: true
    image: quay.io/prometheus/memcached-exporter:v0.11.1

toolbox:
  enabled: false
  priorityClassName: tools
  # requestedMemory: 256Mi
  # requestedCpu: 250m
  # configs:
  #   scheduler:
  #     schedulerConfigurationRef: postgresqlSchedulerConfiguration
  #     celeryConfigurationRef: producerCeleryConfiguration
  #   storage:
  #     storageConfigurationRef: postgresqlStorageConfiguration
  #   scrubber:
  #     scrubberConfigurationRef: postgresScrubberConfiguration
  #   vault:
  #     vaultConfigurationRef: postgresqlVaultConfiguration

vault:
  enabled: false
  priorityClassName: frontend-rpc
  sentry:
    enabled: false
    secretKeyRef: swh-vault-sentry-secret
    secretKeyName: sentry-dsn
  # schedulerConfigurationRef: remoteSchedulerConfiguration
  # vaultConfigurationRef: postgresqlVaultConfiguration
  # storageConfigurationRef: remoteStorageConfiguration
  # objstorageConfigurationRef: remoteObjstorageConfiguration
  # cacheConfigurationRef: azureConfigurationRef
  # logLevel: INFO
  # extraConfig:
  #   smtp:
  #     host: localhost
  #     port: 25
  # The scheduler instance to use for rpc must be a postgresql instance
  # schedulerConfigurationRef: postgresqlSchedulerConfiguration
  # replicas: 2
  # gunicorn:
  #   threads: 5
  #   workers: 2
  #   timeout: 60
  # RPC services may have different profiles than the rest so they need their specific
  # setup
  # requestedMemory: 512Mi
  # requestedCpu: 500m
  # limitedMemory: 512Mi
  # limitedCpu: 500m
  # autoScaling:
  #   minReplicaCount: 2
  #   maxReplicaCount: 10
  #   cpuPercentageUsage: 100
  # ingress:
  #   enabled: false
  #   # Optional: the ingress classname to use
  #   # className: nginx
  #   # mandatory if ingress is enabled
  #   # the hostname on which the storage must be reachable
  #   # host: myscheduler.localdomain
  #   extraAnnotations:
  #     nginx.ingress.kubernetes.io/proxy-connect-timeout: "90"
  #     nginx.ingress.kubernetes.io/proxy-send-timeout: "90"
  #     nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
  #     nginx.ingress.kubernetes.io/proxy-request-buffering: "on"
  #     nginx.ingress.kubernetes.io/proxy-body-size: "4G"
  #   # Default allowed ip ranges that can be extended per ingress definitions paths
  #   # whitelistSourceRangeRef: internalNetworkRanges
  #   # endpoints:
  #   #   default:
  #   #     paths:
  #   #       - /
  #   #   read-only:
  #   #     paths:
  #   #       - /scheduler_metrics/get
  #   #       - /visit_stats/get
  #   #     # Extra allowed ip range for the paths above
  #   #     extraWhitelistSourceRange:
  #   #       - yyy.yyy.yyy.yyy/24

scheduler:
  enabled: false
  priorityClassName: frontend-rpc-workload
  sentry:
    enabled: false
    secretKeyRef: scheduler-sentry-secrets
    secretKeyName: sentry-dsn
  alerts:
    enabled: false
    tooManyMessagesInQueue:
      threshold: 100000
      period: 30m
      severity: warning

  # requestedMemory: 512Mi
  # requestedCpu: 500m
  # schedulerConfigurationRef: remoteSchedulerConfiguration
  # celeryConfigurationRef: guestCeleryConfiguration
  recurrent:
    enabled: false
    logLevel: INFO
    schedulerPolicies:
      default:
      - policy: already_visited_order_by_lag
        weight: 40
      - policy: never_visited_oldest_update_first
        weight: 40
      - policy: origins_without_last_update
        weight: 20
      opam:
      - policy: origins_without_last_update
        weight: 100
  rpc:
    enabled: false
    priorityClassName: frontend-rpc
    logLevel: INFO
    # The scheduler instance to use for rpc must be a postgresql instance
    # schedulerConfigurationRef: postgresqlSchedulerConfiguration
    # replicas: 2
    # gunicorn:
    #   threads: 5
    #   workers: 2
    #   timeout: 60
    # RPC services may have different profiles than the rest so they need their specific
    # setup
    # requestedMemory: 512Mi
    # requestedCpu: 500m
    # limitedMemory: 512Mi
    # limitedCpu: 500m
    # autoScaling:
    #   minReplicaCount: 2
    #   maxReplicaCount: 10
    #   cpuPercentageUsage: 100
    ingress:
      enabled: false
      # Optional: the ingress classname to use
      # className: nginx
      # mandatory if ingress is enabled
      # the hostname on which the storage must be reachable
      # host: myscheduler.localdomain
      extraAnnotations:
        nginx.ingress.kubernetes.io/proxy-connect-timeout: "90"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "90"
        nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
        nginx.ingress.kubernetes.io/proxy-request-buffering: "on"
        nginx.ingress.kubernetes.io/proxy-body-size: "4G"
      # Default allowed ip ranges that can be extended per ingress definitions paths
      # whitelistSourceRangeRef: internalNetworkRanges
      # endpoints:
      #   default:
      #     paths:
      #       - /
      #   read-only:
      #     paths:
      #       - /scheduler_metrics/get
      #       - /visit_stats/get
      #     # Extra allowed ip range for the paths above
      #     extraWhitelistSourceRange:
      #       - yyy.yyy.yyy.yyy/24
  updateMetrics:
    enabled: false
    # It seems to be source of sync issues so deactivated (commented) for now. See [1]
    # for possibly values.
    # [1] # https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#concurrency-policy
    # concurrencyPolicy: Forbid
    # cron: "0/10 * * * *"  # at every 10th minute from 0 to 59
  journalClient:
    enabled: false
    # journalConfigurationRef: journalClientConfiguration
  extraServices:
    runner:
      enabled: false
      logLevel: INFO
      period: 10
    runner-priority:
      # Use dashed (-) name to avoid issues when naming (kube) service
      enabled: false
      logLevel: INFO
      period: 10
      extraConfig:
        - load-bzr
        - load-cvs
        - load-git
        - load-svn
        - load-archive-files
        - load-hg
    listener:
      enabled: false
      logLevel: INFO

# defaultElasticsearchHosts:
#   - host: search-esnode0.internal.staging.swh.network
#     port: 9200

# defaultElasticsearchConfiguration:
#   elasticsearchInstancesRef: defaultElasticsearchHosts
#   cls: elasticsearch
#   indexes:
#     origin:
#       index: origin-v0.11
#       read_alias: origin-read
#       write_alias: origin-write

search:
  enabled: false
  port: 5010
  priorityClassName: frontend-rpc
  sentry:
    enabled: false
    secretKeyRef: swh-search-sentry-secret
    secretKeyName: sentry-dsn
  elasticsearchConfigurationRef: defaultElasticsearchConfiguration
  # logLevel: INFO
  # replicas: 2
  # gunicorn:
  #   threads: 5
  #   workers: 2
  #   timeout: 60
  # RPC services may have different profiles than the rest so they need their specific
  # setup
  # requestedMemory: 512Mi
  # requestedCpu: 500m
  # autoScaling:
  #   minReplicaCount: 2
  #   maxReplicaCount: 10
  #   cpuPercentageUsage: 100
  ingress:
    enabled: false
    # Optional: the ingress classname to use
    # className: nginx
    # mandatory if ingress is enabled
    # the hostname on which the rpc must be reachable
    # host: mysearch.localdomain
    extraAnnotations:
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "90"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "90"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
      nginx.ingress.kubernetes.io/proxy-request-buffering: "on"
      nginx.ingress.kubernetes.io/proxy-body-size: "4G"
      # Default allowed ip ranges that can be extended per ingress definitions paths
      # whitelistSourceRangeRef: internalNetworkRanges
    endpoints:
      default:
        paths:
          - path: /

podPriority:
  enabled: false
  priorities:
    # Note that each priority will be prefixed with its namespace (when declared in the
    # deployment). Because priority have a cluster-wide visibility (independently from
    # its namespace).
    system:
      range: 50000-100000
      value: 75000
      description: Highest pod priorities (ingress, operator, collector, controller)
    storages:
      range: 25000-26000
      value: 25500
      description: Backend storages used by other services (memcached, redis, ...)
    frontend-rpc:
      range: 23000-24000
      value: 24500
      description: Frontend or RPC services (swh-web, swh-graphql, swh-storage, ...)
    frontend-rpc-workload:
      range: 22000-23000
      value: 22500
      description: Frontend or RPC services workload (checker-deposit, loader-deposit, swh-search-journalclient, ...)
    high-workload:
      range: 20000-21000
      value: 20500
      description: High priority workload (save-code-now, add-forge-now, graph computations, ...)
    local-workload:
      range: 10000-15000
      value: 12500
    normal-workload:
      range: 7000-8000
      value: 6500
      description: Normal workload (vault cooker workers, listers, most loaders, ...)
    low-workload:
      range: 5000-6000
      value: 5500
      description: Normal workload (vault cooker workers, listers, most loaders, ...)
    background-storage:
      range: 3000-4000
      value: 3500
      description: Background storage maintenance (reaper, scrubber, ...)
    background-workload:
      range: 1000-2000
      value: 1500
      description: Background workload (replayers cassandra & postgres, redis error reporter, ...)
    tools:
      range: 0-100
      value: 50
      description: Tooling helper (swh-toolbox)

