namespace: swh
environment: production

sentry:
  environment: production

# List of kafka brokers
# used by storage to store the object inserted in the database
# and by the journal clients to follow the storage activiiy
# kafkaBrokers:
#   - myBroker1
#   - myBroker2

# Typical storage's journal writer configuration
# journalWriterConfiguration:
#   brokersConfigurationRef: kafkaBrokers
#   prefix: swh.journal.objects
#   clientId: swh.storage.journal_writer.storage
#   anonymize: true
#   producerConfig:
#     message.max.bytes: 1000000000

# journalClientConfiguration:
#   brokersConfigurationRef: kafkaBrokers
#   group_id: swh.scheduler.journal_client

# postgresqlStorageConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   user: swh
#   pass: ${POSTGRESQL_PASSWORD}
#   db: swh
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-common-secret
#       secretKeyName: postgres-swh-password

# primaryPostgresqlROStorageConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   user: guest
#   pass: ${POSTGRESQL_GUEST_PASSWORD}
#   db: swh
#   secrets:
#     POSTGRESQL_GUEST_PASSWORD:
#       secretKeyRef: swh-postgresql-common-secret
#       secretKeyName: postgres-guest-password

# List of cassandra nodes
# when cassandra is used a backend
# cassandraSeeds:
#   - myCassandraSeeds1
#   - myCassandraSeeds1

# Typical cassandra storage configuration
# cassandraStorageConfiguration:
#   cls: cassandra
#   cassandraSeedsRef: cassandraSeeds
#   keyspace: swh
#   initKeySpace: false
#   consistencyLevel: LOCAL_QUORUM
#   authProvider:
#     cls: cassandra.auth.PlainTextAuthProvider
#     username: swh-rw
#     password: ${CASSANDRA_PASSWORD}
#   specificOptions:
#     directory_entries_insert_algo: batch

# Typical remote storage configuration
# remoteStorageConfiguration:
#   cls: remote
#   host: http://storage:5002

# Typical remote objstorage configuration
# remoteObjstorageConfiguration:
#   cls: remote
#   host: http://objstorage:5003

# searchConfiguration:
#   cls: remote
#   url: http://myswhsearch.localdomain:5010

# djangoWebConfiguration:
#   secrets:
#     DJANGO_SECRET_KEY:
#       secretKeyRef: common-secrets
#       secretKeyName: webapp-django-secret-key

# djangoDepositConfiguration:
#   secrets:
#     DJANGO_SECRET_KEY:
#       secretKeyRef: common-secrets
#       secretKeyName: deposit-django-secret-key

# azureCacheConfiguration:
#   cls: azure
#   connection_string: "DefaultEndpointsProtocol=https;AccountName=account-name;AccountKey=${ACCOUNT_KEY};EndpointSuffix=core.windows.net"
#   container_name: contents
#   compression: none
#   secrets:
#     API_SECRET_KEY:
#       secretKeyRef: swh-vault-azure-secret
#       secretKeyName: azure-swh-vault-key

# azureDepositConfiguration:
#   connection_string:"DefaultEndpointsProtocol=https;AccountName=account-name;AccountKey=${ACCOUNT_KEY};EndpointSuffix=core.windows.net"
#   container_name: container-name
#   secrets:
#     ACCOUNT_KEY:
#       secretKeyRef: swh-deposit-azure-secret
#       secretKeyName: azure-swh-deposit-key

# Example of a storage pipeline configuration
# Adapt according your platform capabilities
# Used by loaders and possibly journal client / replayers
# storageClientPipelineSteps:
#     - cls: buffer
#       min_batch_size:
#         content: 100
#         content_bytes: 52428800
#         directory: 100
#         directory_entries: 500
#         revision: 100
#         revision_parents: 200
#         revision_bytes: 52428800
#         release: 100
#         release_bytes: 52428800
#         extid: 100
#     - cls: filter
#     - cls: retry

# Noop object storage configuration
# noopObjstorageConfiguration:
#   cls: noop

# readWriteObjstorageConfiguration:
#   cls: pathslicing
#   root: "/srv/softwareheritage/objects"
#   slicing: 0:1/1:5
#   client_max_size: 1073741824

# readOnlyObjstorageConfiguration:
#   cls: multiplexer
#   objstorages:
#   - cls: read-only
#     name: first-backend
#     storage:
#       cls: remote
#       url: http://storage1.i.s.o:5003/
#   - cls: read-only
#     name: second-backend
#     storage:
#       cls: remote
#       url: http://storage2.i.s.o:5003/

# Typical storage configuration
# Use references to other entries to assemble
# a complete storage configuration
# Only storageConfigurationRef is mandatory if a remote
# storage is used.
# objstorageConfigurationRef is mandatory for all other
# storage types
#
# defaultStorageClientConfiguration:
#   # pipelineStepsRef: storageClientPipelineSteps

#   # exhaustive supported storage types
#   # storageConfigurationRef: remoteStorageConfiguration
#   storageConfigurationRef: cassandraStorageConfiguration
#   # storageConfigurationRef: postgresqlStorageConfiguration

#   # journalWriterConfigurationRef: journalWriterConfiguration
#   # objstorageConfigurationRef: noopObjstorageConfiguration

# defaultStorageConfiguration:
#   storageConfigurationRef: postgresqlStorageConfiguration
#   objectStorageConfiguration: remoteObjectStorageConfiguration

# defaultIndexerStorageConfiguration:
#   cls: postgresql
#   host: indexer-storage.server
#   db: swh-indexer
#   port: 5432
#   user: swh
#   pass: ${POSTGRESQL_PASSWORD}
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-indexer-storage-postgresql-secret
#       secretKeyName: postgres-swh-indexer-password

# globalROStorageConfiguration:
# TODO: define this configuration

# postgresqlWebConfiguration:
#   host: postgresql-web-rw.internal.softwareheritage.org
#   port: 5432
#   db: swh-web
#   user: swh-web
#   pass: ${POSTGRESQL_PASSWORD}
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-web-secret
#       secretKeyName: postgres-swh-web-password

# postgresqlDepositConfiguration:
#   host: postgresql-deposit-rw.internal.softwareheritage.org
#   port: 5432
#   db: swh-deposit
#   user: swh-deposit
#   pass: ${POSTGRESQL_PASSWORD}
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-deposit-secret
#       secretKeyName: postgres-swh-deposit-password

# postgresqlSchedulerConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   user: swh-scheduler
#   pass: ${POSTGRESQL_PASSWORD}
#   db: swh
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-common-secret
#       secretKeyName: postgres-swh-password

# postgresqlVaultConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   db: swh-vault
#   user: swh-vault
#   password: ${POSTGRESQL_PASSWORD}
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-vault-secret
#       secretKeyName: postgres-swh-vault-password

# scrubberPostgresqlDatabaseConfiguration
#   cls: postgresql
#   host: mydatabase-server
#   port: '5432'
#   db: scrubber
#   user: scrubber
#   pass: ${POSTGRESQL_PASSWORD}
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-common-secret
#       secretKeyName: postgres-scrubber-password

# remoteSchedulerConfiguration:
#   cls: remote
#   url: http://scheduler.internal.staging.swh.network

# guestCeleryConfiguration:
#   host: scheduler0.internal.staging.swh.network
#   port: 5672
#   user: guest
#   pass: ${AMQP_PASSWORD}
#   secrets:
#     AMQP_PASSWORD:
#       secretKeyRef: amqp-secrets
#       secretKeyName: guest-password

# producerCeleryConfiguration:
#   host: scheduler0.internal.staging.swh.network
#   port: 5672
#   user: swhproducer
#   pass: ${AMQP_PASSWORD}
#   secrets:
#     AMQP_PASSWORD:
#       secretKeyRef: amqp-secrets
#       secretKeyName: swhproducer-password

# consumerCeleryConfiguration:
#   host: scheduler0.internal.staging.swh.network
#   port: 5672
#   user: swhconsumer
#   pass: ${AMQP_PASSWORD}
#   secrets:
#     AMQP_PASSWORD:
#       secretKeyRef: amqp-secrets
#       secretKeyName: swhconsumer-password

# depositConfiguration:
#   host:
#   user: ${DEPOSIT_USERNAME}
#   pass: ${DEPOSIT_PASSWORD}
#   secrets:
#     DEPOSIT_USER:
#       secretKeyRef: deposit-secrets
#       secretKeyName: read-write
#     DEPOSIT_PASSWORD:
#       secretKeyRef: deposit-secrets
#       secretKeyName: read-write

# remoteVaultConfiguration:
#   cls: remote
#   url: http://<vault service url>

# remoteIndexerStorageConfiguration:
#   cls: remote
#   url: http://<indexer storage service url>

# remoteCountersConfiguration
#   cls: remote
#   url: http://<counters service url>

# defaultJournalWriterConfiguration:
#   brokersConfigurationRef: kafkaBrokers
#   clientId: swh.storage.journal_writer.storage1
#   producerConfig: |-
#     message.max.bytes: 1000000000
#     item2: value2
#     item3: value3
#   # optional values with their default value
#   prefix: swh.journal.objects
#   anonymize: true

# keycloakConfiguration:
#   server_url: https://my.keycloak.instance/auth/
#   realm_name: myrealm

# countersConfiguration:
#   cls: redis
#   host: localhost:6379

# historyCountersConfiguration:
#   cls: prometheus
#   prometheus_host: thanos.i.a.s.n
#   prometheus_port: 19191
#   live_data_start: 1609462861
#   interval: 12h
#   labels:
#     environment: staging

giveConfiguration:
  public: ${GIVE_PUBLIC_KEY}
  token: ${GIVE_PRIVATE_TOKEN}
  secrets:
    GIVE_PUBLIC_KEY:
      secretKeyRef: web-give-secrets
      secretKeyName: public-key
    GIVE_PRIVATE_TOKEN:
      secretKeyRef: web-give-secrets
      secretKeyName: private-token

graphql:
  enabled: false
  port: 5013
  priorityClassName: frontend-rpc
  # Those are globally defined but can be overwritten per instance
  logLevel: INFO
  anonymousUserMaxQueryCost: 50
  authenticatedUserMaxQueryCost: 500
  debug: no
  introspection: yes
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: graphql-sentry-dsn
  deployments:
    instance-name:
      enabled: false
      # logLevel: INFO
      # debug: no
      # introspection: yes
      # # requestedMemory: 150Mi
      # # requestedCpu: 50m
      # # maxQueryCost for anonymous users
      # anonymousUserMaxQueryCost: 50
      # authenticatedUserMaxQueryCost: 500
      #  # check defaultStorageConfiguration example to configure your storage
      #  storageConfigurationRef: defaultROStorageClientConfiguration
      #  searchConfigurationRef: searchConfiguration
      #  ingress:
      #    enabled: false
      #    host: my_host # Optional
      #    extraAnnotations:
      #      nginx.ingress.kubernetes.io/rewrite-target: /
      #    endpoints:
      #      default:
      #        paths:
      #          - path: /
      # auth:
      #   enabled: false
      #   # More information in https://gitlab.softwareheritage.org/swh/devel/swh-auth/-/blob/master/README.rst
      #   # server: https://auth.backend.url/
      #   # optional, when not provided, graphql defaults to use "server" entry
      #   # public_server: https://another.auth.backend.url/
      #   # realm: MyAuthDomain
      #   client: swh-web
      #   # memory:// or memcached://memcached:port
      #   cacheUrl: memory://
      # maxRawContentSize: 10000

# Allow to specify a specific configuration for pod's /tmp
# directory. Mostly used to configure the loaders to work
# on specific tmpfs on the nodes.
# It can be necessary when using a memory emptyDir is not sufficient
tmpEphemeralStorage:
  claimTemplate: {}
    # ephemeral:
    #   volumeClaimTemplate:
    #     metadata:
    #       labels:
    #         type: ephemeral-volume
    #     spec:
    #       accessModes: [ "ReadWriteOnce" ]
    #       storageClassName: "local-path"
    #       resources:
    #         requests:
    #           storage: 100Gi # no effects
  # workaround because helm merges the map values when overridden
  # It shouldn't have to be modified
  default:
    emptyDir: {}

storage_replayer:
  enabled: false
  priorityClassName: background-workload
  maxMessagesBytes: "524288000"
  journalBrokers:
    # The name of the secret containing the BROKER_USER_PASSWORD value
    # secretName: storage-replayer-broker-secret
    hosts:
    - broker1
    - broker2
    user: myuser
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageReplayerConfiguration
  # optional 'replayer' configuration may be specified with a 'error_reporter' config
  # entry allowing to specify redis connection parameters. It will be used to report
  # non-recoverable replaying issues
  # error_reporter:
  #   host: redis.redis
  #   port: 6379
  #   db: 1

  # When true, check db & code versions and do not start if they diverge
  checkDbVersion: false

  deployments:
  # Example of deployments
  #   origins:
  #     privileged: false
  #     objects:
  #       - origin
  #       - origin_visits
  #       - origin_visits_status
  #     batchSize: 250
  #   revisions:
  #     privileged: false
  #     objects:
  #       - revision
  #     batchSize: 1000
  #     autoScaling:
  #       poolInterval: 120
  #       lagThreshold: 1000
  #       minReplicaCount: 1
  #       maxReplicaCount: 10

loader_metadata:
  enabled: false
  priorityClassName: normal-workload
  sentrySwhPackage: swh.loader.metadata
  requestedMemory: 350Mi
  requestedCpu: 80m
  # Override the default dns configuration (ndots, search domains, ...)
  # dnsConfiguration: dnsConfiguration
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageClientConfiguration
  # schedulerConfigurationRef: defaultSchedulerConfiguration
  # consumerGroup: ...
  # prefix: swh.journal.objects
  # reload_after_days: 120
  # journalBrokers:
  #   hosts:
  #     - ...
  #   user: ...
  autoScaling:
    enabled: true
  #   poolInterval: 120
  #   lagThreashold: 1000
  #   minReplicaCount: 1
  #   maxReplicaCount: 10

loaders:
  enabled: false
  priorityClassName: normal-workload
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageClientConfiguration
  # celeryConfigurationRef: consumerCeleryConfiguration
  # sysctls:
  #   net.ipv4.tcp_dsack: 0
  # Override global loaders dns configuration (can be changed per loader too)
  # dnsConfigurationRef: dnsConfigurationRef
  deployments:
  # Example of deployments
    # git:
    #   requestedMemory: 256Mi
    #   requestedCpu: 200m
    #   dnsConfigurationRef: dnsConfigurationRef
    #   queues:
    #     - swh.loader.git.tasks.UpdateGitRepository
    #   sysctls:
    #     net.ipv4.tcp_dsack: 0
    #   autoScaling:
    #     # Downscale to 0 loaders when the queue is empty
    #     stopWhenNoActivity: false
    #     queueThreshold: 10  # spawn worker per increment of `value` messages
    #     minReplicacount: 1
    #     maxReplicaCount: 3

cookers:
  enabled: false
  priorityClassName: normal-workload
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # celeryConfigurationRef: consumerCeleryConfiguration
  # vaultConfigurationRef: remoteVaultConfiguration
  autoScaling:
    queueThreshold: 1

checker_deposit:
  enabled: false
  priorityClassName: frontend-rpc-workload
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # celeryConfigurationRef: consumerCeleryConfiguration
  depositConfigurationRef: depositConfiguration
  autoScaling:
    cooldownPeriod: 3600

indexers:
  enabled: false
  priorityClassName: frontend-rpc
  sentrySwhPackage: swh.indexer
  # schedulerConfigurationRef: remoteSchedulerConfiguration
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  journalClientConfigurationRef: journalClientConfiguration
  # deployments:
  #  foo:
  #    journalClientOverrides:
  #      group_id: my-group-id
  #    # If defined, autoscaling configuration should not be defined
  #    replicas: 1
  #    # If defined, replicas configuration should not be defined
  #    # if sasl is activated on the connection, the kafka username must
  #    # be configured in a secret to allow the keda autoscaling to work
  #    autoScaling:
  #      poolInterval: 120
  #      lagThreashold: 1000
  #      minReplicaCount: 1
  #      maxReplicaCount: 5
  #      stopWhenNoActivity: true
  #      lagThreshold: 1000

listers:
  enabled: false
  priorityClassName: normal-workload
  # General autoScaling option, this can be overridden per instance
  autoScaling:
    queueThreshold: 1
    cooldownPeriod: 3600
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # schedulerConfigurationRef: defaultSchedulerConfiguration
  # celeryConfigurationRef: consumerCeleryConfiguration

indexerStorage:
  enabled: false
  port: 5007
  priorityClassName: frontend-rpc
  logLevel: INFO
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: indexer-sentry-dsn
  backend:
    # When true, initalize the backend, leave it empty to do nothing
    # initialize:
    #   adminSecret: vault-superuser
    #   database: swh-vault
    # When true, check db & code versions and do not start if they diverge
    check: false
    # When true, migrate or initialize db model
    migrate: false
  deployments:
    # rpc:
    #   # Don't configure the replicas if autoscaling is configured
    #   # and vice-versa
    #   # replicas: 1
    #   requestedCpu: 50m
    #   requestedMemory: 100Mi
    #   # autoScaling:
    #   #   minReplicaCount: 2
    #   #   maxReplicaCount: 10
    #   #   cpuPercentageUsage: 100
    #   #  affinity:
    #   #    nodeAffinity:
    #   #      requiredDuringSchedulingIgnoredDuringExecution:
    #   #        nodeSelectorTerms:
    #   #        - matchExpressions:
    #   #          - key: "swh/rpc"
    #   #            operator: In
    #   #            values:
    #   #            - "true"
    #   #  gunicorn:
    #   #    threads: 5
    #   #    workers: 2
    #   #    timeout: 60
    #   # mandatory
    #   # check defaultStorageConfiguration example to configure your storage
    #   # indexerStorageConfigurationRef: defaultIndexerStorageConfiguration
    #   # journalWriteConfigurationRef: defaultJournalWriterConfiguration
    #   # When true, check db & code versions and do not start if they diverge
    #   checkDbVersion: false
    #   # Deploy an ingress to access the storage
    #   ingress:
    #     enabled: false
    #     # Optional: the ingress classname to use
    #     # className: nginx
    #     # mandatory if ingress is enabled
    #     # the hostname on which the storage must be reachable
    #     # host: mystorage.localdomain
    #     endpoints:
    #       default:
    #         paths:
    #           - path: /

storage:
  enabled: false
  port: 5002
  priorityClassName: frontend-rpc
  logLevel: INFO
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: storage-sentry-dsn
  #  affinity:
  #    nodeAffinity:
  #      requiredDuringSchedulingIgnoredDuringExecution:
  #        nodeSelectorTerms:
  #        - matchExpressions:
  #          - key: "swh/storage"
  #            operator: In
  #            values:
  #            - "true"
  # Whether to do extra actions on the backend used by the storage
  backend:
    # When true, initalize the backend, leave it empty to do nothing
    # initialize:
    #   adminSecret: storage-superuser
    #   database: swh
    # When true, check db & code versions and do not start if they diverge
    check: false
    # When true, migrate or initialize db model
    migrate: false
  deployments:
    # postgresql:
    #   # loglevel can be overriden per instance
    #   logLevel: WARN
    #   # rpc port can be overriden per instance
    #   # port: 5002
    #   # Don't configure the replicas if autoscaling is configured
    #   # and vice-versa
    #   # replicas: 1
    #   backend:
    #     # When true, initalize the backend
    #     initialize: false
    #     # When true, check db & code versions and do not start if they diverge
    #     check: false
    #     # When true, migrate or initialize db model
    #     migrate: false
    #   requestedCpu: 50m
    #   requestedMemory: 100Mi
    #   # autoScaling:
    #   #   minReplicaCount: 2
    #   #   maxReplicaCount: 10
    #   #   cpuPercentageUsage: 100
    #   # gunicorn:
    #   #   threads: 5
    #   #   workers: 2
    #   #   timeout: 60
    #   # mandatory
    #   # check defaultStorageConfiguration example to configure your storage
    #   # storageConfigurationRef: defaultStorageConfiguration
    #   # Deploy an ingress to access the storage
    #   ingress:
    #     enabled: false
    #     # Optional: the ingress classname to use
    #     # className: nginx

    #     # mandatory if ingress is enabled
    #     # the hostname on which the storage must be reachable
    #     # host: mystorage.localdomain
    #     endpoints:
    #       default:
    #         paths:
    #           - path: /
    #   cronjobs:
    #     create-object-reference-partitions:
    #       enabled: true
    #       logLevel: INFO
    #       cron: 5 0 * * mon

# internalNetworkRanges:
#   - xxx.xxx.xxx.xxx/24
#   - yyy.yyy.yyy.yyy/24

# externalNetworkRanges:
#   - zzz.zzz.zzz.zzz/24

# throttlingConfiguration:
#   internalExemptedNetworkRangesRef: internalNetworkRanges
#   externalExemptedNetworkRangesRef: externalNetworkRanges
#   # The memcached url, mandatory
#   cache_uri: memcached:11211
#   # rate limit with some network exception
#   scopes_with_exempted_networks:
#     # Possible other scopes are
#     # - swh_api_origin_visit_latest
#     # - swh_vault_cooking
#     # - swh_save_origin
#     # - swh_raw_object
#     swh_api:
#       limiter_rate:
#         default: 120/h
#     swh_api_origin_search:
#       limiter_rate:
#         default: 120/h
#       exempted_networks:
#         - aaa.aaa.aaa.aaa/24
#   # rate limit without any network exemption
#   scopes:
#     # Possible other scopes are
#     # - swh_save_origin
#     # - swh_raw_object
#     swh_api_origin_visit_latest:
#       limiter_rate:
#         default: 120/h
#     swh_vault_cooking:
#       limiter_rate:
#         default: 120/h

web:
  enabled: false
  port: 5004
  logLevel: INFO
  migrations:
    enabled: false
  priorityClassName: frontend-rpc
  extraPorts:
    webstatic: 80
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: web-sentry-dsn
  deployments:
    instance:
      enabled: false
      # can be overriden per instance
      # port: 5004
      # extraPorts:
      #   webstatic: 80
      # migrations:
      #   enabled: truew
      # logLevel: INFO
      # # debug: false
      # requestedCpu: 50m
      # requestedMemory: 100Mi
      # nginxRequestedCpu: 10m
      # nginxRequestedMemory: 50m
      # replicas: 1
      # autoScaling:
      #   minReplicaCount: 2
      #   maxReplicaCount: 10
      #   cpuPercentageUsage: 50
      refreshSavecodenowStatus:
        enabled: false
        priorityClassName: frontend-rpc-workload
        logLevel: INFO
        # concurrencyPolicy: Forbid
        # Every 2 minute
        cron: "*/2 * * * *"
      syncMailmaps:
        enabled: false
        priorityClassName: frontend-rpc-workload
        logLevel: INFO
        # concurrencyPolicy: Forbid
        # At minute 15 every hour
        cron: "15 * * * *"
     # gunicorn:
     #   threads: 5
     #   workers: 2
     #   timeout: 60
      # host: webapp
      ingress:
        enabled: false
        # extraAnnotations:
        #   cert-manager.io/cluster-issuer: letsencrypt-production-gandi
        #   kubernetes.io/ingress.class: nginx
        #   kubernetes.io/tls-acme: "true"
        #   nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
        # tlsEnabled: true
        # whitelistSourceRangeRef: internalNetworkRanges
        endpoints:
          default:
            paths:
              - path: /
              - path: /static
                port: 80
          # authenticated:
          #   paths:
          #     - path: /api/1/provenance/
          #     - path: /api/1/entity/
          #     - path: /api/1/content/[^/]+/symbol/
          #   # auth-file with authentication
          #   authentication: swh/ingress-auth
      # searchConfigurationRef: searchConfiguration
      # # Configure the scheduler instance used for save code now requests
      # schedulerConfigurationRef: schedulerConfiguration
      # storageConfigurationRef: globalROStorageConfiguration
      # vaultConfigurationRef: remoteVaultConfiguration
      # indexerStorageConfigurationRef: remoteIndexerStorageConfiguration
      # countersConfigurationRef: remoteCountersConfiguration
      # djangoConfigurationRef: djangoWebConfiguration
      # # If not specified, this will use a sqlite db which is not performant enough for
      # # production use.
      # databaseConfigurationRef: postgresqlWebConfiguration
      # depositConfigurationRef: depositConfiguration
      # giveConfigurationRef: giveConfiguration
      # throttlingConfigurationRef: throttlingConfiguration
      # keycloakConfigurationRef: keycloakConfiguration
      # extraConfig:
      #   debug: false
      #   history_counters_url: http://elastichost.swh.org:5011/counters_history/history.json
      #   es_workers_index_url: http://elastichost.swh.org:9200/swh_workers-*
      #   search_config:
      #     # swh-indexer-storage or swh-search
      #     metadata_backend: swh-indexer-storage
      #   # max content size in bytes
      #   content_display_max_size: 5242880
      #   swh_extra_django_apps:
      #     - swh.web.add_forge_now
      #     - swh.web.archive_coverage
      #     - swh.web.badges
      #     - swh.web.banners
      #     - swh.web.deposit
      #     - swh.web.inbound_email
      #     - swh.web.jslicenses
      #     - swh.web.mailmap
      #     - swh.web.metrics
      #     - swh.web.save_code_now
      #     - swh.web.save_origin_webhooks
      #     - swh.web.vault
      #   add_forge_now:
      #     email_address: add-forge-now@archive.swh.org
      #   deposit:
      #     private_api_url: "https://deposit-rp.i.s.s.n/1/private/"
      #     private_api_user: "${DEPOSIT_USERNAME}"
      #     private_api_password: "${DEPOSIT_PASSWORD}"
      #   give:
      #     public_key: ${GIVE_PUBLIC_KEY}
      #     token: ${GIVE_PRIVATE_TOKEN}

statsd_exporter:
  enabled: false
  priorityClassName: system
  image: prom/statsd-exporter
  imageVersion: "v0.26.0"

memcached:
  # Deploy a memcached instance used by the webapp and graphql for sessions caching
  enabled: false
  priorityClassName: storages
  image: memcached:1.6.23
  memory: 256
  requestedCpu: 100m
  requestedMemory: 300Mi
  prometheus:
    # Activate the deployment of the memcached exporter and ServiceMonitor
    enabled: true
    image: quay.io/prometheus/memcached-exporter:v0.14.2

toolbox:
  enabled: false
  priorityClassName: tools
  # requestedMemory: 256Mi
  # requestedCpu: 250m
  # configs:
  #   scheduler:
  #     schedulerDbConfigurationRef: postgresqlSchedulerConfiguration
  #     celeryConfigurationRef: producerCeleryConfiguration
  #   storage:
  #     storageDbConfigurationRef: postgresqlStorageConfiguration
  #   scrubber-journal:
  #     scrubberDbConfigurationRef: postgresScrubberConfiguration
  #     journalClientConfigurationRef: journalClientConfiguration
  #   vault:
  #     vaulDbtConfigurationRef: postgresqlVaultConfiguration

externalServices:
  enabled: false
  services:
    # vault:
    #   # Configure to create a CNAME equivalent to the ingress controller service. This
    #   # allows to use the ingress internally and avoid recording an external dns entry.
    #   # Unstable & subject to change
    #   internalName: vault-rpc
    #   target: ingress-nginx-controller.ingress-nginx.svc.cluster.local

vault:
  enabled: false
  port: 5005
  priorityClassName: frontend-rpc
  sentry:
    enabled: false
    secretKeyRef: swh-vault-sentry-secret
    secretKeyName: sentry-dsn
  backend:
    # When true, initalize the backend, leave it empty to do nothing
    # initialize:
    #   adminSecret: vault-superuser
    #   database: swh-vault
    # When true, check db & code versions and do not start if they diverge
    check: false
    # When true, migrate or initialize db model
    migrate: false
  # schedulerConfigurationRef: remoteSchedulerConfiguration
  # vaultConfigurationRef: postgresqlVaultConfiguration
  # storageConfigurationRef: remoteStorageConfiguration
  # objstorageConfigurationRef: remoteObjstorageConfiguration
  # cacheConfigurationRef: azureConfigurationRef
  # logLevel: INFO
  # extraConfig:
  #   smtp:
  #     host: localhost
  #     port: 25
  # The scheduler instance to use for rpc must be a postgresql instance
  # schedulerConfigurationRef: postgresqlSchedulerConfiguration
  # replicas: 2
  # gunicorn:
  #   threads: 5
  #   workers: 2
  #   timeout: 60
  # RPC services may have different profiles than the rest so they need their specific
  # setup
  # requestedMemory: 512Mi
  # requestedCpu: 500m
  # limitedMemory: 512Mi
  # limitedCpu: 500m
  # autoScaling:
  #   minReplicaCount: 2
  #   maxReplicaCount: 10
  #   cpuPercentageUsage: 100
  # ingress:
  #   enabled: false
  #   # Optional: the ingress classname to use
  #   # className: nginx
  #   # mandatory if ingress is enabled
  #   # the hostname on which the vault must be reachable
  #   host: vault-rpc
  #   extraAnnotations:
  #     nginx.ingress.kubernetes.io/proxy-connect-timeout: "90"
  #     nginx.ingress.kubernetes.io/proxy-send-timeout: "90"
  #     nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
  #     nginx.ingress.kubernetes.io/proxy-request-buffering: "on"
  #     nginx.ingress.kubernetes.io/proxy-body-size: "4G"
  #   # Default allowed ip ranges that can be extended per ingress definitions paths
  #   # whitelistSourceRangeRef: internalNetworkRanges
  #   endpoints:
  #     default:
  #       paths:
  #         - path: /
  #     read-only:
  #       paths:
  #         - path: /scheduler_metrics/get
  #         - path: /visit_stats/get
  #       # Extra allowed ip range for the paths above
  #       extraWhitelistSourceRange:
  #         - yyy.yyy.yyy.yyy/24

scheduler:
  enabled: false
  port: 5008
  priorityClassName: frontend-rpc-workload
  sentry:
    enabled: false
    secretKeyRef: scheduler-sentry-secrets
    secretKeyName: sentry-dsn
  alerts:
    enabled: false
    # period: 30m
    # severity: warning
    # tooManyMessagesInQueue:
      # threshold: 100000
      # instances:
      #   rabbitmq-node:
      #     # can be overriden at the instance alert level
      #     threshold: 100000
      #     # can be overriden at the instance alert level
      #     period: 30m
      #     severity: warning

  # requestedMemory: 512Mi
  # requestedCpu: 500m
  # schedulerConfigurationRef: remoteSchedulerConfiguration
  # celeryConfigurationRef: guestCeleryConfiguration
  recurrent:
    enabled: false
    logLevel: INFO
    schedulerPolicies:
      default:
      - policy: already_visited_order_by_lag
        weight: 40
      - policy: never_visited_oldest_update_first
        weight: 40
      - policy: origins_without_last_update
        weight: 20
      opam:
      - policy: origins_without_last_update
        weight: 100
      git-checkout:
      - policy: origins_without_last_update
        weight: 100
      hg-checkout:
      - policy: origins_without_last_update
        weight: 100
      svn-export:
      - policy: origins_without_last_update
        weight: 100
      tarball-directory:
      - policy: origins_without_last_update
        weight: 100
      content:
      - policy: origins_without_last_update
        weight: 100
      git:
      - policy: origins_without_last_update
        weight: 85
        tablesample: 0.1
      - policy: never_visited_oldest_update_first
        weight: 10
        tablesample: 0.1
      - policy: already_visited_order_by_lag
        weight: 5
        tablesample: 0.1
  rpc:
    enabled: false
    port: 5008
    priorityClassName: frontend-rpc
    logLevel: INFO
    backend:
      # When true, initalize the backend, leave it empty to do nothing
      # initialize:
      #   adminSecret: scheduler-superuser
      #   database: swh-scheduler
      # When true, check db & code versions and do not start if they diverge
      check: false
      # When true, migrate or initialize db model
      migrate: false
      # When true, register the scheduler task types
      register: false

    # The scheduler instance to use for rpc must be a postgresql instance
    # schedulerConfigurationRef: postgresqlSchedulerConfiguration
    # replicas: 2
    # gunicorn:
    #   threads: 5
    #   workers: 2
    #   timeout: 60
    # RPC services may have different profiles than the rest so they need their specific
    # setup
    # requestedMemory: 512Mi
    # requestedCpu: 500m
    # limitedMemory: 512Mi
    # limitedCpu: 500m
    # autoScaling:
    #   minReplicaCount: 2
    #   maxReplicaCount: 10
    #   cpuPercentageUsage: 100
    ingress:
      enabled: false
      # Optional: the ingress classname to use
      # className: nginx
      # mandatory if ingress is enabled
      # the hostname on which the storage must be reachable
      # host: myscheduler.localdomain
      extraAnnotations:
        nginx.ingress.kubernetes.io/proxy-connect-timeout: "90"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "90"
        nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
        nginx.ingress.kubernetes.io/proxy-request-buffering: "on"
        nginx.ingress.kubernetes.io/proxy-body-size: "4G"
      # Default allowed ip ranges that can be extended per ingress definitions paths
      # whitelistSourceRangeRef: internalNetworkRanges
      # endpoints:
      #   default:
      #     paths:
      #       - path: /
      #   read-only:
      #     paths:
      #       - path: /scheduler_metrics/get
      #       - path: /visit_stats/get
      #     # Extra allowed ip range for the paths above
      #     extraWhitelistSourceRange:
      #       - yyy.yyy.yyy.yyy/24
  updateMetrics:
    enabled: false
    # It seems to be source of sync issues so deactivated (commented) for now. See [1]
    # for possibly values.
    # [1] # https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#concurrency-policy
    # concurrencyPolicy: Forbid
    # cron: "0/10 * * * *"  # at every 10th minute from 0 to 59
  journalClient:
    enabled: false
    # journalConfigurationRef: journalClientConfiguration
  extraServices:
    runner:
      enabled: false
      logLevel: INFO
      period: 10
    runner-priority:
      # Use dashed (-) name to avoid issues when naming (kube) service
      enabled: false
      logLevel: INFO
      period: 10
      extraConfig:
        - load-bzr
        - load-cvs
        - load-git
        - load-svn
        - load-archive-files
        - load-hg
    listener:
      enabled: false
      logLevel: INFO

# defaultElasticsearchHosts:
#   - host: search-esnode0.internal.staging.swh.network
#     port: 9200

# defaultElasticsearchConfiguration:
#   elasticsearchInstancesRef: defaultElasticsearchHosts
#   cls: elasticsearch
#   indexes:
#     origin:
#       index: origin-v0.11
#       read_alias: origin-read
#       write_alias: origin-write

search:
  enabled: false
  port: 5010
  priorityClassName: frontend-rpc
  sentry:
    enabled: false
    secretKeyRef: swh-search-sentry-secret
    secretKeyName: sentry-dsn
  elasticsearchConfigurationRef: defaultElasticsearchConfiguration
  # logLevel: INFO
  # replicas: 2
  # gunicorn:
  #   threads: 5
  #   workers: 2
  #   timeout: 60
  # RPC services may have different profiles than the rest so they need their specific
  # setup
  # requestedMemory: 512Mi
  # requestedCpu: 500m
  # autoScaling:
  #   minReplicaCount: 2
  #   maxReplicaCount: 10
  #   cpuPercentageUsage: 100
  ingress:
    enabled: false
    # Optional: the ingress classname to use
    # className: nginx
    # mandatory if ingress is enabled
    # the hostname on which the rpc must be reachable
    # host: mysearch.localdomain
    extraAnnotations:
      nginx.ingress.kubernetes.io/proxy-connect-timeout: "90"
      nginx.ingress.kubernetes.io/proxy-send-timeout: "90"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
      nginx.ingress.kubernetes.io/proxy-request-buffering: "on"
      nginx.ingress.kubernetes.io/proxy-body-size: "4G"
      # Default allowed ip ranges that can be extended per ingress definitions paths
      # whitelistSourceRangeRef: internalNetworkRanges
    endpoints:
      default:
        paths:
          - path: /
  journalClients:
    enabled: false
    # priorityClassName: normal-workload
    # searchConfigurationRef: searchConfiguration
    # storageConfigurationRef: remoteStorageConfiguration
    # deployments:
    #   objects:
    #     journalConfigurationRef: journalObjectConfiguration
    #     # requestedCpu: 100m
    #     # requestedMemory: 500Mi
    #     # journalClientOverrides:
    #     # # Declare specific journal client overrides for this consummer
    #         # group_id: my-search-group-id
    #         # prefix: swh.journal.objects
    #         # object_types:
    #         #   - object1
    #         #   - object2
    #   indexed:
    #     journalConfigurationRef: journalIndexedConfiguration

# journalObjectConfiguration:
#   brokersConfigurationRef: kafkaBrokers
#   group_id: swh.search.journal_client-v0.11
#   prefix: swh.journal.objects
#   object_types:
#   - origin
#   - origin_visit_status

# journalIndexedConfiguration:
#   brokersConfigurationRef: kafkaBrokers
#   group_id: swh.search.journal_client.indexed-v0.11
#   prefix: swh.journal.indexed
#   object_types:
#   - origin_intrinsic_metadata
#   - origin_extrinsic_metadata

scrubber:
  enabled: false
  # priorityClassName: background-workload
  scrubberDatabaseConfigurationRef: scrubberDatabaseConfiguration
  sentry:
    enabled: false
    # Mandatory if enabled
    # secretKeyRef: swh-scrubber-sentry-secret
    # secretKeyName: sentry-dsn
  # affinity:
  #   nodeAffinity:
  #     requiredDuringSchedulingIgnoredDuringExecution:
  #       nodeSelectorTerms:
  #       - matchExpressions:
  #         - key: "swh/rpc"
  #           operator: In
  #           values:
  #           - "true"
  storageChecker:
    enabled: false
    # # default configuration of the storage
    # # it must have a direct access to the database (class postgresql or cassandra)
    # # It can be overriden by instance
    # storageConfigurationRef: primaryPostgresqlROStorageConfiguration
    # deployments:
    #   object:
    #     enabled: false
    #     configName: mydb-directory
    #     # logLevel: INFO
    #     # override of the storage configuration
    #     # storageConfigurationRef: otherPostgresqlROStorageConfiguration
    #     # the kind of object to check
    #     # must be one of the following:
    #     #   - directory
    #     #   - release
    #     #   - revision
    #     #   - snapshot
    #     object: directory
    #     # replicas: 1
    #     # requestedCpu: 500m
    #     # requestedMemory: 512Mi
    #     # limitedCpu:
    #     # limitedMemory:
  journalChecker:
    enabled: false
    journalClientConfigurationRef: journalClientConfiguration
    deployments:
      # can be split per object type for more control
      # The journal client group id will be suffixed with this name
      # directory:
        # enabled: false
        # The configName must be used to register the config with
        # the swh scrubber init
        # configName: mydb-directory
        # logLevel: INFO
        # Supported object: snapshot, revision, release, directory
        # object: directory
        # batchSize: 1000
        # replicas: 1
        # requestedCpu: 500m
        # requestedMemory: 512Mi
        # limitedCpu:
        # limitedMemory:

deposit:
  enabled: false
  port: 5006
  extraPorts:
    webstatic: 80
  migrationsEnabled: false
  priorityClassName: frontend-rpc
  # debug: false
  logLevel: INFO
  requestedCpu: 50m
  requestedMemory: 100Mi
  # replicas: 1
  # autoScaling:
  #   minReplicaCount: 2
  #   maxReplicaCount: 10
  #   cpuPercentageUsage: 50
  # gunicorn:
  #   threads: 5
  #   workers: 2
  #   timeout: 60
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: deposit-sentry-dsn
  # hosts:
  # - deposit.staging.swh.network
  ingress:
    enabled: false
  #   extraAnnotations:
  #     cert-manager.io/cluster-issuer: letsencrypt-production-gandi
  #     kubernetes.io/ingress.class: nginx
  #     kubernetes.io/tls-acme: "true"
  #     nginx.ingress.kubernetes.io/force-ssl-redirect: "true"
  #   tlsEnabled: true
  #   whitelistSourceRangeRef: internalNetworkRanges
    endpoints:
      default:
        paths:
          - path: /
  # schedulerConfigurationRef: schedulerConfiguration
  # storageConfigurationRef: globalROStorageConfiguration
  # storageMetadataConfigurationRef: remoteStorageMetadataConfiguration
  # djangoConfigurationRef: djangoDepositConfiguration
  # databaseConfigurationRef: postgresqlDepositConfiguration
  # keycloakConfigurationRef: keycloakConfiguration
  # blobstorageConfigurationRef: azureDepositConfiguration
  # extraConfig:
  #   max_upload_size: 209715200
  #   extraction_dir: "/tmp/swh-deposit/archive/"
  #   authentication_provider: keycloak
  #   cache_uri: 127.0.0.1:11211

objstorage:
  enabled: false
  port: 5003
  priorityClassName: frontend-rpc
  logLevel: INFO
#  affinity:
#    nodeAffinity:
#      requiredDuringSchedulingIgnoredDuringExecution:
#        nodeSelectorTerms:
#        - matchExpressions:
#          - key: "swh/objstorage"
#            operator: In
#            values:
#            - "true"
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: objstorage-sentry-dsn

  deployments:
    # Each key will be an objstorage instance to be deployed
    # The mandatory objstorageConfigurationRef key should target a dict
    # with the specific objstorage configuration
    # read-write:
    #   enabled: false
    #   # # Log level can be overridden per instance
    #   # logLevel: WARN
    #   # # rpc port can be changed per deployment
    #   # port: 5003
    #   # requestedCpu: 50m
    #   # requestedMemory: 100Mi
    #   # gunicorn:
    #   #   threads: 5
    #   #   workers: 2
    #   #   timeout: 60
    #   # autoScaling:
    #   #   minReplicaCount: 2
    #   #   maxReplicaCount: 10
    #   #   cpuPercentageUsage: 100
    #   # mandatory objstorage configuration reference
    #   # check readWriteStorageConfiguration example to configure your storage
    #   objstorageConfigurationRef: readWriteObjstorageConfiguration
    #   # A list of extra volumes to mount within the pod container.
    #   # For example for the case of a pathslicing objstorage (that needs access to a
    #   # Directory folder on the machine node hosting the pod container)
    #   volumes:
    #     some-volume:
    #       mountPath: /path/to/mount
    #       volumeDefinition:
    #         hostPath:  # kind (supported by kubernetes)
    #           path: /path/to/mount
    #           type: Directory
    #   # hosts:
    #   # - myobjstorage.local
    #   # Deploy an ingress to access the objstorage
    #   ingress:
    #     enabled: false
    #     # mandatory if ingress is enabled
    #     # the hostname on which the objstorage must be reachable
    #     # Optional: the ingress classname to use
    #     # className: nginx
    #     endpoints:
    #       default:
    #         paths:
    #           - path: /

    # read-only:
    #   enabled: false
    #   objstorageConfigurationRef: readOnlyObjstorageConfiguration

podPriority:
  enabled: false
  priorities:
    # Note that each priority will be prefixed with its namespace (when declared in the
    # deployment). Because priority have a cluster-wide visibility (independently from
    # its namespace).
    system:
      range: 50000-100000
      value: 75000
      description: Highest pod priorities (ingress, operator, collector, controller)
    storages:
      range: 25000-26000
      value: 25500
      description: Backend storages used by other services (memcached, redis, ...)
    frontend-rpc:
      range: 23000-24000
      value: 24500
      description: Frontend or RPC services (swh-web, swh-graphql, swh-storage, ...)
    frontend-rpc-workload:
      range: 22000-23000
      value: 22500
      description: Frontend or RPC services workload (checker-deposit, loader-deposit, swh-search-journalclient, ...)
    high-workload:
      range: 20000-21000
      value: 20500
      description: High priority workload (save-code-now, add-forge-now, graph computations, ...)
    local-workload:
      range: 10000-15000
      value: 12500
    normal-workload:
      range: 7000-8000
      value: 6500
      description: Normal workload (vault cooker workers, listers, most loaders, ...)
    tools:
      range: 0--100
      value: -50
      description: Tooling helper (swh-toolbox)
    low-workload:
      range: -5000--6000
      value: -5500
      description: Normal workload (vault cooker workers, listers, most loaders, ...)
    background-storage:
      range: -8000--9000
      value: -8500
      description: Background storage maintenance (scrubber, ...)
    background-workload:
      range: -10000--11000
      value: -10500
      description: Background workload (replayers cassandra & postgres, ...)

webhooks:
  enabled: false
  sentry:
    enabled: false
  #affinity:
  #  nodeAffinity:
  #    requiredDuringSchedulingIgnoredDuringExecution:
  #      nodeSelectorTerms:
  #      - matchExpressions:
  #        - key: swh/webhooks
  #          operator: In
  #          values:
  #          - "true"
  #svixConfigurationRef: svixConfiguration
  #journalClientConfigurationRef: journalClientConfiguration
  #priorityClassName: frontend-rpc-workload
  #deployments:
  #  origin-visit-status:
  #    replicas: 1
  #    requestedCpu: 100m
  #    requestedMemory: 100Mi
  #    journalClientOverrides:
  #      group_id: my-webhook-group-id
  #      auto_offset_reset: latest
  #      object_types:
  #        - origin_visit_status

counters:
  enabled: false
  port: 5011
  sentry:
    enabled: true
    secretKeyRef: common-secrets
    secretKeyName: counters-sentry-dsn
  refreshCountersCache:
    enabled: false
    cron: "0 */4 * * *"
    concurrencyPolicy: Forbid
    countersConfigurationRef: remoteCountersConfiguration
    historyFiles:
      - history.json
      - static_history.json
  rpc:
    enabled: false
    fetchStaticHistory: false
    cacheBaseDirectory: /srv/softwareheritage/counters
    priorityClassName: frontend-rpc
    logLevel: INFO
    # The scheduler instance to use for rpc must be a postgresql instance
    # countersConfigurationRef: countersConfiguration
    # historyConfigurationRef: historyCountersConfiguration
    # replicas: 2
    # gunicorn:
    #   threads: 5
    #   workers: 2
    #   timeout: 60
    # RPC services may have different profiles than the rest so they need their specific
    # setup
    # requestedMemory: 512Mi
    # requestedCpu: 500m
    # limitedMemory: 512Mi
    # limitedCpu: 500m
    # autoScaling:
    #   minReplicaCount: 2
    #   maxReplicaCount: 10
    #   cpuPercentageUsage: 100
    # If true, it will deploy a ServiceMonitor to store the counters values in prometheus.
    # It's used by the /refresh_metrics endpoint to generate the temporal data for the webapp
    # graphics
    # scrapeMetrics: false
    ingress:
      enabled: false
      # Optional: the ingress classname to use
      # className: nginx
      # mandatory if ingress is enabled
      # the hostname on which the storage must be reachable
      # host: myscheduler.localdomain
      extraAnnotations:
        nginx.ingress.kubernetes.io/proxy-connect-timeout: "90"
        nginx.ingress.kubernetes.io/proxy-send-timeout: "90"
        nginx.ingress.kubernetes.io/proxy-read-timeout: "3600"
        nginx.ingress.kubernetes.io/proxy-request-buffering: "on"
        nginx.ingress.kubernetes.io/proxy-body-size: "4G"
      # Default allowed ip ranges that can be extended per ingress definitions paths
      # whitelistSourceRangeRef: internalNetworkRanges
      # endpoints:
      #   default:
      #     paths:
      #       - path: /
      #   read-only:
      #     paths:
      #       - path: /scheduler_metrics/get
      #       - path: /visit_stats/get
      #     # Extra allowed ip range for the paths above
      #     extraWhitelistSourceRange:
      #       - yyy.yyy.yyy.yyy/24
  journalClient:
    enabled: false
    # countersConfigurationRef: remoteCountersConfiguration
    # journalConfigurationRef: journalClientCountersConfiguration

objstorageReplayer:
  enabled: false
  # journalClientConfigurationRef: journalClientConfiguration
  # sourceObjstorageConfigurationRef: fakeRemoteObjstorageConfiguration
  # destinationObjstorageConfigurationRef: fakeRemoteObjstorageConfiguration
  # sentry:
  #   enabled: false
  #   secretKeyRef: my-secret
  #   secretKeyName: my-key
  # deployments:
  #  other-objstorage:
  #    journalClientOverrides:
  #      group_id: my-group-id
  #    destinationObjstorageConfigurationRef: targetRWObjstorageConfigurtion
  #    sourceObjectStorageConfigurationRef: sourceROObjstorageConfiguration
  #    fetchConcurrency: 2
  #    # If defined, autoscaling configuration should not be defined
  #    replicas: 1
  #    # If defined, replicas configuration should not be defined
  #    # if sasl is activated on the connection, the kafka username must
  #    # be configured in a secret to allow the keda autoscaling to work
  #    autoScaling:
  #      poolInterval: 120
  #      lagThreashold: 1000
  #      minReplicaCount: 1
  #      maxReplicaCount: 5
  #      stopWhenNoActivity: true
  #      lagThreshold: 1000

cassandraChecks:
  enabled: false
  logLevel: INFO
  # priorityClassName: swh-background-workload
  # directoryOutput: /volume/cassandra-checks
  # volume:
  #   name: cassandra-checks-volume
  #   mountPath: /volume
  #   readOnly: false
  #   volumeDefinition:  # either disk setup
  #     hostPath:
  #       path: /volume
  #       type: Directory
  #   volumeDefinition:  # or pvc claim setup (report to <volumeClaim> key)
  #     persistentVolumeClaim:
  #       claimName: cassandra-checks-pvc
  # volumeClaim:  # Specific pvc to declare
  #   storageClassName: cephfs
  #   name: cassandra-checks-pvc
  #   size: 20Gi
  # volumeSize: 8Gi
  # storagePostgresqlConfigurationRef: storagePostgresqlConfiguration
  # storageCassandraConfigurationRef: storageCassandraConfiguration
  # journalClientConfigurationRef: journalClientConfiguration
  # deployments:
  #   content:
  #     replicas: 2
  #     journalClientOverrides:
  #       object_type:
  #         - content
  #       batch_size: 1000
  #   # Those can be large, so the batch is smaller
  #   directory:
  #     replicas: 2
  #       object_type:
  #         - directory
  #     journalClientOverrides:
  #       batch_size: 100
  #   # We need the authenticated & privileged access to compare revision
  #   revision:
  #     replicas: 2
  #     journalClientOverrides:
  #       object_type:
  #         - revision
  #       batch_size: 100
  #       privileged: true
  #   # We need the authenticated & privileged access to compare revision
  #   release:
  #     replicas: 2
  #     journalClientOverrides:
  #       object_type:
  #         - release
  #       batch_size: 1000
  #       privileged: true
  #   origin:
  #     replicas: 2
  #     journalClientOverrides:
  #       object_type:
  #         - origin
  #         - origin_visit
  #         - origin_visit_status
  #       batch_size: 1000
  #   metadata:
  #     replicas: 2
  #     journalClientOverrides:
  #       object_type:
  #         - extid
  #         - raw_extrinsic_metadata
  #       batch_size: 1000
  #   snapshot:
  #     replicas: 2
  #     journalClientOverrides:
  #       object_type:
  #         - snapshot
  #       batch_size: 1000

storage_backfiller:
  enabled: false
  # # pin versions to avoid stopping jobs during new deployment
  # imageVersion: '20240603.1'
  # swhUtilsImageVersion: '20231211.1'
  # priorityClassName: background-workload
  # deployments:
  #   # Example of deployment
  #   content:
  #     enabled: true
  #     checkDbVersion: true
  #     storageConfigurationRef: ROStorageConfiguration
  #     journalConfigurationRef: storageJournalWriterConfiguration
  #     object_type: raw_extrinsic_metadata
  #     ranges: 1
  #     prefix: swh:1:cnt
  #     requestedCpu: 450m
  #     requestedMemory: 1200Mi
