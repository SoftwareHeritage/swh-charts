namespace: swh

sentry:
  environment: production

# List of kafka brokers
# used by storage to store the object inserted in the database
# and by the journal clients to follow the storage activiiy
# kafkaBrokers:
#   - myBroker1
#   - myBroker2

# Typical storage's journal writer configuration
# journalWriterConfiguration:
#   kafkaBrokersRef: kafkaBrokers
#   prefix: swh.journal.objects
#   clientId: swh.storage.journal_writer.storage
#   anonymize: true
#   producerConfig:
#     message.max.bytes: 1000000000

# journalClientConfiguration:
#   kafkaBrokersRef: kafkaBrokers
#   groupId: swh.scheduler.journal_client

# postgresqlStorageConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   user: swh
#   password: ${POSTGRESQL_PASSWORD}
#   db: swh
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-common-secret
#       secretKeyName: postgres-swh-password

# List of cassandra nodes
# when cassandra is used a backend
# cassandraSeeds:
#   - myCassandraSeeds1
#   - myCassandraSeeds1

# Typical cassandra storage configuration
# cassandraStorageConfiguration:
#   cls: cassandra
#   cassandraSeedsRef: cassandraSeeds
#   keyspace: swh
#   initKeySpace: false
#   consistencyLevel: LOCAL_QUORUM
#   authProvider:
#     cls: cassandra.auth.PlainTextAuthProvider
#     username: swh-rw
#     password: ${CASSANDRA_PASSWORD}
#   specificOptions:
#     directory_entries_insert_algo: batch

# Typical remote storage configuration
# remoteStorageConfiguration:
#   cls: remote
#   host: http://storage:5002

# Example of a storage pipeline configuration
# Adapt according your platform capabilities
# Used by loaders and possibly journal client / replayers
# storageClientPipelineSteps:
#     - cls: buffer
#       min_batch_size:
#         content: 100
#         content_bytes: 52428800
#         directory: 100
#         directory_entries: 500
#         revision: 100
#         revision_parents: 200
#         revision_bytes: 52428800
#         release: 100
#         release_bytes: 52428800
#         extid: 100
#     - cls: filter
#     - cls: retry

# Noop object storage configuration
# noopObjectStorage:
#   cls: noop

# Typical storage configuration
# Use references to other entries to assemble
# a complete storage configuration
# Only storageConfigurationRef is mandatory if a remote
# storage is used.
# objectStorageConfigurationRef is mandatory for all other
# storage types
#
# defaultStorageClientConfiguration:
#   # pipelineStepsRef: storageClientPipelineSteps

#   # exhaustive supported storage types
#   # storageConfigurationRef: remoteStorageConfiguration
#   storageConfigurationRef: cassandraStorageConfiguration
#   # storageConfigurationRef: postgresqlStorageConfiguration

#   # journalWriterConfigurationRef: journalWriterConfiguration
#   # objectStorageConfigurationRef: noopObjectStorage

# defaultStorageConfiguration:
#   storageConfigurationRef: postgresqlStoragecConfiguration
#   objectStorageConfiguration: remoteObjectStorageConfiguration

# globalROStorageConfiguration:
# TODO: define this configuration and use it for the webapp

# postgresqlSchedulerConfiguration:
#   cls: postgresql
#   host: mydatabasese.server
#   port: '5432'
#   user: swh-scheduler
#   password: ${POSTGRESQL_PASSWORD}
#   db: swh
#   secrets:
#     POSTGRESQL_PASSWORD:
#       secretKeyRef: swh-postgresql-common-secret
#       secretKeyName: postgres-swh-password

# remoteSchedulerConfiguration:
#   cls: remote
#   host: scheduler0.internal.staging.swh.network
#   port: 5008

# readOnlyCeleryConfiguration:
#   host: scheduler0.internal.staging.swh.network
#   port: 5672
#   user: guest
#   pass: ${AMQP_PASSWORD}
#   secrets:
#     AMQP_PASSWORD:
#       secretKeyRef: amqp-secrets
#       secretKeyName: read-only

# readWriteCeleryConfiguration:
#   host: scheduler0.internal.staging.swh.network
#   port: 5672
#   user: guest
#   pass: ${AMQP_PASSWORD}
#   secrets:
#     AMQP_PASSWORD:
#       secretKeyRef: amqp-secrets
#       secretKeyName: read-write

graphql:
  enabled: false
  priorityClassName: swh-frontend-rpc
  logLevel: INFO
  debug: no
  introspection: yes
  # requestedMemory: 150Mi
  # requestedCpu: 50m
  # maxQueryCost for anonymous users
  anonymousUserMaxQueryCost: 50
  authenticatedUserMaxQueryCost: 500
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: graphql-sentry-dsn
#    # check defaultStorageConfiguration example to configure your storage
#    storageConfigurationRef: defaultROStorageClientConfiguration
#    searchConfiguration:
#      host: http://my-search
#      port: 5010
#  ingress:
#    enabled: false
#    httpPath: /graphql
#    host: my_host # Optional
  auth:
    enabled: false
    # More information in https://gitlab.softwareheritage.org/swh/devel/swh-auth/-/blob/master/README.rst
    # server: https://auth.backend.url/
    # optional, when not provided, graphql defaults to use "server" entry
    # public_server: https://another.auth.backend.url/
    #realm: MyAuthDomain
    client: swh-web
    # memory:// or memcached://memcached:port
    cacheUrl: memory://
  # maxRawContentSize: 10000

# Allow to specify a specific configuration for pod's /tmp
# directory. Mostly used to configure the loaders to work
# on specific tmpfs on the nodes.
# It can be necessary when using a memory emptyDir is not sufficient
tmpEphemeralStorage:
  claimTemplate: {}
    # ephemeral:
    #   volumeClaimTemplate:
    #     metadata:
    #       labels:
    #         type: ephemeral-volume
    #     spec:
    #       accessModes: [ "ReadWriteOnce" ]
    #       storageClassName: "local-path"
    #       resources:
    #         requests:
    #           storage: 100Gi # no effects
  # workaround because helm merges the map values when overridden
  # It shouldn't have to be modified
  default:
    emptyDir: {}

storage_replayer:
  enabled: false
  priorityClassName: swh-background-workload
  maxMessagesBytes: "524288000"
  journalBrokers:
    # The name of the secret containing the BROKER_USER_PASSWORD value
    # secretName: storage-replayer-broker-secret
    hosts:
    - broker1
    - broker2
    user: myuser
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageReplayerConfiguration
  # optional 'replayer' configuration may be specified with a 'error_reporter' config
  # entry allowing to specify redis connection parameters. It will be used to report
  # non-recoverable replaying issues
  # error_reporter:
  #   host: redis.redis
  #   port: 6379
  #   db: 1

  # Don't start if code and database versions are not equals
  # Only supported for postgresql backend
  checkDbVersion: false

  deployments:
  # Example of deployments
  #   origins:
  #     privileged: false
  #     objects:
  #       - origin
  #       - origin_visits
  #       - origin_visits_status
  #     batchSize: 250
  #   revisions:
  #     privileged: false
  #     objects:
  #       - revision
  #     batchSize: 1000
  #     autoScaling:
  #       poolInterval: 120
  #       lagThreashold: 1000
  #       minReplicaCount: 1
  #       maxReplicaCount: 10

loader_metadata:
  enabled: false
  priorityClassName: swh-normal-workload
  sentrySwhPackage: swh.loader.metadata
  requestedMemory: 350Mi
  requestedCpu: 80m
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageClientConfiguration
  # schedulerConfigurationRef: defaultSchedulerConfiguration
  # consumerGroup: ...
  # prefix: swh.journal.objects
  # reload_after_days: 120
  # journalBrokers:
  #   hosts:
  #     - ...
  #   user: ...
  autoScaling:
    enabled: true
  #   poolInterval: 120
  #   lagThreashold: 1000
  #   minReplicaCount: 1
  #   maxReplicaCount: 10

loaders:
  enabled: false
  priorityClassName: swh-normal-workload
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageClientConfiguration
  # celeryConfigurationRef: readWriteCeleryConfiguration
  deployments:
  # Example of deployments
    # git:
    #   requestedMemory: 256Mi
    #   requestedCpu: 200m
    #   queues:
    #     - swh.loader.git.tasks.UpdateGitRepository
    #   autoScaling:
    #     # Downscale to 0 loaders when the queue is empty
    #     stopWhenNoActivity: false
    #     queueThreshold: 10  # spawn worker per increment of `value` messages
    #     minReplicacount: 1
    #     maxReplicaCount: 3

cookers:
  enabled: false
  priorityClassName: swh-normal-workload
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # celeryConfigurationRef: readWriteCeleryConfiguration


checker_deposit:
  enabled: false
  priorityClassName: swh-frontend-rpc-workload
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # celeryConfigurationRef: readWriteCeleryConfiguration

indexers:
  enabled: false
  priorityClassName: frontend-rpc
  sentrySwhPackage: swh.indexer
  # schedulerConfigurationRef: remoteSchedulerConfiguration
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration

listers:
  enabled: false
  priorityClassName: swh-normal-workload
  # terminationGracePeriodSeconds: 3600
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultReadOnlyStorageClientConfiguration
  # schedulerConfigurationRef: defaultSchedulerConfiguration
  # celeryConfigurationRef: readWriteCeleryConfiguration

storage:
  enabled: false
  priorityClassName: frontend-rpc
  logLevel: INFO
# Don't configure the replicas if autoscaling is configured
# and vice-versa
# replicas: 1
  requestedCpu: 50m
  requestedMemory: 100Mi
# autoScaling:
#   minReplicaCount: 2
#   maxReplicaCount: 10
#   cpuPercentageUsage: 100
#  affinity:
#    nodeAffinity:
#      requiredDuringSchedulingIgnoredDuringExecution:
#        nodeSelectorTerms:
#        - matchExpressions:
#          - key: "swh/storage"
#            operator: In
#            values:
#            - "true"
#  gunicorn:
#    threads: 5
#    workers: 2
#    timeout: 60
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: storage-sentry-dsn
  # mandatory
  # check defaultStorageConfiguration example to configure your storage
  storageConfigurationRef: defaultStorageConfiguration

  # Don't start if code and database versions are not equals
  # Only supported for postgresql backend
  checkDbVersion: false

  objstorage:
    cls: noop
  ##  if objstorage configuration doesn't contains passwords or sensitive data
  # objstorageClass: filtered
  # objstorageConfig:
  #   storage_conf:
  #     cls: remote
  #     url: http://storage1.internal.staging.swh.network:5003/
  #   filters_conf:
  #   - type: readonly
  ## if objstorage configuration contains passwords or sensitive data
  ## /!\ the configmap indentation (10) had to be defined in the secret
  # objstorageClass: multiplexer
  # objstorageConfig: ${OBJSTORAGECONFIG}

  # Deploy an ingress to access the storage
  ingress:
    enabled: false
    # Optional: the ingress classname to use
    # className: nginx

    # mandatory if ingress is enabled
    # the hostname on which the storage must be reachable
    # host: mystorage.localdomain

  ## if journal access is required
  ## mandatory values
  #journalWriter:
  #  brokers:
  #    - kafka1
  #    - kafka2
  #    - kafka3
  #  clientId: swh.storage.journal_writer.storage1
  #  producerConfig: |-
  #    message.max.bytes: 1000000000
  #    item2: value2
  #    item3: value3
  ## optional values with their default value
  #  prefix: swh.journal.objects
  #  anonymize: true

web:
  enabled: false
  priorityClassName: swh-frontend-rpc
  logLevel: INFO
  replicas: 1
  requestedCpu: 50m
  requestedMemory: 100Mi
  autoScaling:
    maxReplicaCount: 1
#  affinity:
#    nodeAffinity:
#      requiredDuringSchedulingIgnoredDuringExecution:
#        nodeSelectorTerms:
#        - matchExpressions:
#          - key: swh/web
#            operator: In
#            values:
#            - "true"
#  gunicorn:
#    threads: 5
#    workers: 2
#    timeout: 60
  sentry:
    enabled: false
    # name of the secret containing the $secretKeyName value
    # it defines the sentry token, host and projet to access
    # like https://token@sentry.host/id
    secretKeyRef: common-secrets
    secretKeyName: web-sentry-dsn
  configSecretRef: swh-cassandra-webapp-config

statsd_exporter:
  enabled: false
  priorityClassName: swh-system
  image: prom/statsd-exporter
  imageVersion: "v0.22.7"

memcached:
  # Deploy a memcached instance used by the webapp and graphql for sessions caching
  enabled: false
  priorityClassName: swh-storages
  image: memcached:1.6.18
  memory: 256m
  requestedCpu: 100m
  requestedMemory: 300Mi
  prometheus:
    # Activate the deployment of the memcached exporter and ServiceMonitor
    enabled: true
    image: quay.io/prometheus/memcached-exporter:v0.11.1

toolbox:
  enabled: false
  priorityClassName: swh-tools
  # requestedMemory: 256Mi
  # requestedCpu: 250m
  # configs:
  #   scheduler:
  #      schedulerConfigurationRef: postgresqlSchedulerConfiguration
  #      celeryConfigurationRef: readWriteCeleryConfiguration
  #   storage: postgresqlStorageConfiguration

scheduler:
  enabled: false
  priorityClassName: swh-frontend-rpc-workload
  sentry:
    enabled: false
    secretKeyRef: scheduler-sentry-secrets
    secretKeyName: sentry-dsn
  # requestedMemory: 512Mi
  # requestedCpu: 500m
  # schedulerConfigurationRef: remoteSchedulerConfiguration
  # celeryConfigurationRef: readOnlyCeleryConfiguration
  recurrent:
    enabled: false
    logLevel: INFO
    schedulerPolicies:
      default:
      - policy: already_visited_order_by_lag
        weight: 40
      - policy: never_visited_oldest_update_first
        weight: 40
      - policy: origins_without_last_update
        weight: 20
      opam:
      - policy: origins_without_last_update
        weight: 100
  # runner:
  #   enabled: false
  # runnerPriority:
  #   enabled: false
  # listener:
  #   enabled: false
  rpc:
    enabled: false
    priorityClassName: swh-frontend-rpc
    logLevel: INFO
    # The scheduler instance to use for rpc must be a postgresql instance
    # schedulerConfigurationRef: postgresqlSchedulerConfiguration
    # replicas: 2
    # gunicorn:
    #   threads: 5
    #   workers: 2
    #   timeout: 60
    # RPC services may have different profiles than the rest so they need their specific
    # setup
    # requestedMemory: 512Mi
    # requestedCpu: 500m
    # limitedMemory: 512Mi
    # limitedCpu: 500m
    # autoScaling:
    #   minReplicaCount: 2
    #   maxReplicaCount: 10
    #   cpuPercentageUsage: 100
    ingress:
      enabled: false
      # Optional: the ingress classname to use
      # className: nginx
      # mandatory if ingress is enabled
      # the hostname on which the storage must be reachable
      # host: myscheduler.localdomain
  updateMetrics:
    enabled: false
    # It seems to be source of sync issues so deactivated (commented) for now. See [1]
    # for possibly values.
    # [1] # https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#concurrency-policy
    # concurrencyPolicy: Forbid
    cron: "0/10 * * * *"  # at every 10th minute from 0 to 59
  journalClient:
    enabled: false
    # journalConfigurationRef: journalClientConfiguration
  extraServices:
    runner:
      enabled: false
      logLevel: INFO
      period: 10
    runner-priority:
      # Use dashed (-) name to avoid issues when naming (kube) service
      enabled: false
      logLevel: INFO
      period: 10
      extraConfig:
        - load-bzr
        - load-cvs
        - load-git
        - load-svn
        - load-archive-files
        - load-hg
    listener:
      enabled: false
      logLevel: INFO

podPriority:
  enabled: false
  priorities:
    swh-system:
      range: 50000-100000
      value: 75000
      description: Highest pod priorities (ingress, operator, collector, controller)
    swh-storages:
      range: 25000-26000
      value: 25500
      description: Backend storages used by other services (memcached, redis, ...)
    swh-frontend-rpc:
      range: 23000-24000
      value: 24500
      description: Frontend or RPC services (swh-web, swh-graphql, swh-storage, ...)
    swh-frontend-rpc-workload:
      range: 22000-23000
      value: 22500
      description: Frontend or RPC services workload (checker-deposit, swh-search-journalclient, ...)
    swh-high-workload:
      range: 20000-21000
      value: 20500
      description: High priority workload (save-code-now, add-forge-now, graph computations, ...)
    swh-local-workload:
      range: 10000-15000
      value: 12500
    swh-normal-workload:
      range: 7000-8000
      value: 6500
      description: Normal workload (vault cooker workers, listers, most loaders, ...)
    swh-low-workload:
      range: 5000-6000
      value: 5500
      description: Normal workload (vault cooker workers, listers, most loaders, ...)
    swh-background-storage:
      range: 3000-4000
      value: 3500
      description: Background storage maintenance (reaper, scrubber, ...)
    swh-background-workload:
      range: 1000-2000
      value: 1500
      description: Background workload (replayers cassandra & postgres, redis error reporter, ...)
    swh-tools:
      range: 0-100
      value: 50
      description: Tooling helper (swh-toolbox)

