namespace: swh-cassandra-next-version

postgresqlWebConfiguration:
  host: next-version-dbs-rw.swh-cassandra-next-version
  port: 5432
  db: swh-web
  user: swh-web
  pass: ${POSTGRESQL_PASSWORD}
  secrets:
    POSTGRESQL_PASSWORD:
      secretKeyRef: swh-postgresql-web-secrets
      secretKeyName: postgres-swh-web-password

postgresqlVaultConfiguration:
  host: next-version-dbs-rw.swh-cassandra-next-version
  port: 5432
  db: swh-vault
  user: swh-vault
  pass: ${POSTGRESQL_PASSWORD}
  secrets:
    POSTGRESQL_PASSWORD:
      secretKeyRef: swh-vault-postgresql-secret
      secretKeyName: postgres-swh-vault-password

postgresqlSchedulerConfiguration:
  host: next-version-dbs-rw.swh-cassandra-next-version
  port: 5432
  db: swh-scheduler
  user: swh-scheduler
  pass: ${POSTGRESQL_PASSWORD}
  secrets:
    POSTGRESQL_PASSWORD:
      secretKeyRef: swh-scheduler-postgresql-common-secret
      secretKeyName: postgres-swh-scheduler-password

celeryConfiguration:
  host: rabbitmq-scheduler
  port: 5672
  user: ${AMQP_USERNAME}
  pass: ${AMQP_PASSWORD}
  secrets:
    AMQP_USERNAME:
      secretKeyRef: rabbitmq-scheduler-secret
      secretKeyName: username
    AMQP_PASSWORD:
      secretKeyRef: rabbitmq-scheduler-secret
      secretKeyName: password

postgresqlRWStorageConfiguration:
  cls: postgresql
  host: next-version-swh-rw
  port: '5432'
  db: swh
  user: ${POSTGRESQL_USERNAME}
  pass: ${POSTGRESQL_PASSWORD}
  secrets:
    POSTGRESQL_USERNAME:
      secretKeyRef: swh-postgresql-swh-swh-secret
      secretKeyName: username
    POSTGRESQL_PASSWORD:
      secretKeyRef: swh-postgresql-swh-swh-secret
      secretKeyName: password

remotePostgresqlStorageConfiguration:
  cls: remote
  url: http://storage-rw-postgresql:5002

remoteCassandraStorageConfiguration:
  cls: remote
  url: http://storage-rw-cassandra:5002

remoteRWStorageWithPipelineConfiguration:
  pipelineStepsRef: storagePipelineSteps
  storageConfigurationRef: remoteCassandraStorageConfiguration

rwStoragePostgresqlConfiguration:
  storageConfigurationRef: postgresqlRWStorageConfiguration
  objstorageConfigurationRef: noopObjstorageConfiguration

retryStoragePipelineSteps:
  - cls: retry

remoteROStorageConfiguration:
  pipelineStepsRef: retryStoragePipelineSteps
  storageConfigurationRef: remotePostgresqlStorageConfiguration

remoteVaultConfiguration:
  cls: remote
  url: http://vault-rpc-ingress-next-version

remoteSchedulerConfiguration:
  cls: remote
  url: http://scheduler-rpc:5008

vault:
  replicas: 1
  vaultConfigurationRef: postgresqlVaultConfiguration
  autoScaling:
    minReplicaCount: 1
    maxReplicaCount: 1
  backend:
    # check db version with latest code?
    check: true
    # migrate db?
    migrate: false
  hosts:
    - vault-rpc-ingress-next-version

remoteCountersConfiguration:
  cls: remote
  url: http://counters-rpc:5011

externalServices:
  enabled: true
  services:
    vault:
      internalName: vault-rpc-ingress-next-version
      target: archive-staging-rke2-ingress-nginx-controller.ingress-nginx.svc.cluster.local
    counters:
      internalName: counters-rpc-ingress-next-version
      target: archive-staging-rke2-ingress-nginx-controller.ingress-nginx.svc.cluster.local

countersJournalClientConfiguration:
  brokersConfigurationRef: internalSecuredKafkaBrokers
  group_id: swh-counters-journal-client
  prefix: swh.journal.objects
  object_types:
  - content
  - directory
  - origin
  - origin_visit
  - origin_visit_status
  - release
  - revision
  - skipped_content
  - snapshot
  message.max.bytes: 524288000

localRedis:
  cls: redis
  host: redis-counters:6379

counters:
  enabled: true
  journalClient:
    enabled: true
    countersConfigurationRef: remoteCountersConfiguration
    journalConfigurationRef: countersJournalClientConfiguration
  refreshCountersCache:
    enabled: false
    cron: "0 */1 * * *"
    concurrencyPolicy: Forbid
    countersConfigurationRef: remoteCountersConfiguration
    historyFiles: []
  rpc:
    enabled: true
    cacheBaseDirectory: /tmp/counters
    countersConfigurationRef: localRedis
    # historyConfigurationRef: historyConfiguration
    replicas: 1
    ingress:
      enabled: false

loaders:
  terminationGracePeriodSeconds: 60
  storageConfigurationRef: remoteRWStorageWithPipelineConfiguration
  celeryConfigurationRef: celeryConfiguration
  deployments:
    # Force the deployment of one pod of each type to at least
    # ensure they start (not enough but it's a first step)
    add-forge-now:
      enabled: false
    add-forge-now-slow:
      enabled: false
    archive:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    bzr:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    cran:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    cvs:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    content:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    directory:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    git:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    git-checkout:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    hg-checkout:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    svn-export:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    debian:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    deposit:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    golang:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    save-code-now:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    maven:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    mercurial:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    npm:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    opam:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    pypi:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    pubdev:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false
    svn:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        stopWhenNoActivity: false

loaderMetadata:
  terminationGracePeriodSeconds: 60
  autoScaling:
    queueThreshold: 1
    maxReplicaCount: 1
    # TODO: Support this option
    # stopWhenNoActivity: false

cassandraRWNoObjstorageStorageConfig:
  storageConfigurationRef: cassandraStorage
  objstorageConfigurationRef: noopObjstorageConfiguration

storageReplayerJournalClientConfig:
  cls: kafka
  brokersConfigurationRef: internalSecuredKafkaBrokers
  prefix: swh.journal.objects
  message.max.bytes: "524288000"
  # Both to write some data to privileged topic and use the error_reporter config
  privileged: true

storageReplayer:
  enabled: true
  storageConfigurationRef: cassandraRWNoObjstorageStorageConfig
  journalClientConfigurationRef: storageReplayerJournalClientConfig
  error_reporter:
    enabled: false
  # Force the deployment of one pod of each type to at least
  # ensure they start (not enough but it's a first step)
  deployments:
    content:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    directory:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    extid:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    metadata:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    raw-extrinsic-metadata:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    origin:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    origin-visit:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    origin-visit-status:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    release:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    revision:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    skipped-content:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false
    snapshot:
      autoScaling:
        queueThreshold: 1
        maxReplicaCount: 1
        # TODO: Support this option
        # stopWhenNoActivity: false

cassandraSeeds:
  - cassandra-cluster-next-version-service

cassandraStorage:
  cls: cassandra
  cassandraSeedsRef: cassandraSeeds
  keyspace: swh
  initKeyspace: true
  consistencyLevel: LOCAL_QUORUM
  specificOptions:
    directory_entries_insert_algo: batch
  authProvider:
    cls: cassandra.auth.PlainTextAuthProvider
    username: ${CASSANDRA_USERNAME}
    password: ${CASSANDRA_PASSWORD}
  secrets:
    CASSANDRA_USERNAME:
      secretKeyRef: cassandra-cluster-superuser
      secretKeyName: username
    CASSANDRA_PASSWORD:
      secretKeyRef: cassandra-cluster-superuser
      secretKeyName: password

noopObjstorageConfiguration:
  cls: noop

readWriteInternalKafkaBrokers:
  - kafka-cluster-kafka-brokers:9092

internalSecuredKafkaBrokers:
  - kafka-cluster-kafka-brokers:9092

storageJournalWriterConfiguration:
  brokersConfigurationRef: readWriteInternalKafkaBrokers
  prefix: swh.journal.objects
  clientId: swh-storage-journal-writer
  producerConfig:
    message.max.bytes: 1000000000

pathslicingObjstorageConfiguration:
  cls: pathslicing
  root: "/srv/swh/objects"
  slicing: 0:1/1:5
  client_max_size: 1073741824
  allow_delete: true

objstorage:
  enabled: true
  priorityClassName: frontend-rpc
  # For mounting the volume with the right permission
  # docker image has the `swh` uid set at 1005
  securityContext:
    fsGroup: 1005
  deployments:
    # Each key will be an objstorage instance to be deployed
    # The mandatory objstorageConfigurationRef key should target a dict
    # with the specific objstorage configuration

    # Deactivate instances from swh/values/staging/swh-cassandra.yaml
    db1-read-write:
      enabled: false
    storage1-read-only:
      enabled: false
    db1-read-only:
      enabled: false
    multiplexer-read-only:
      enabled: false
    multiplexer-read-write:
      enabled: false
    # Activate dedicated instance for write workload
    rw-pathslicing:
      enabled: true
      replicas: 1
      extraVolumes:
        pathslicing-rw:
          mountPath: /srv/swh/objects
          volumeDefinition:
            ephemeral:
              volumeClaimTemplate:
                metadata:
                  labels:
                    type: persistent-volume
                spec:
                  accessModes:
                  - ReadWriteOnce
                  resources:
                    requests:
                      storage: 10Gi
                  storageClassName: local-persistent

      # mandatory
      # check readWriteStorageConfiguration example to configure your storage
      objstorageConfigurationRef: pathslicingObjstorageConfiguration

rpcRWObjstoragePathslicingConfiguration:
  cls: remote
  url: http://objstorage-rw-pathslicing:5003

rwStorageCassandraWithJournalConfiguration:
  storageConfigurationRef: cassandraStorage
  journalWriterConfigurationRef: storageJournalWriterConfiguration
  objstorageConfigurationRef: rpcRWObjstoragePathslicingConfiguration

storage:
  deployments:
    # Deactivate those instance in swh-cassandra-next-version namespace
    cassandra:  # Instance name from the swh-cassandra.yaml file
      enabled: false
    # Deactivate those instance in swh-cassandra-next-version namespace
    cassandra-read-only:  # Instance name from the swh-cassandra.yaml file
      enabled: false
    # main storage to let the loaders write
    rw-cassandra:
      storageConfigurationRef: rwStorageCassandraWithJournalConfiguration
    # a storage postgresql instance to replay data
    rw-postgresql:
      enabled: true
      storageConfigurationRef: rwStoragePostgresqlConfiguration
      backend:
        initialize:
          adminSecret: next-version-swh-superuser
          database: swh
        check: false
        migrate: false

webhooksConfiguration: {}

web:
  deployments:
    cassandra:
      databaseConfigurationRef: postgresqlWebConfiguration
      searchConfigurationRef: remoteSearchConfiguration
      schedulerConfigurationRef: remoteSchedulerConfiguration
      vaultConfigurationRef: remoteVaultConfiguration
      indexerStorageConfigurationRef: remoteIndexerStorageConfiguration
      countersConfigurationRef: remoteCountersConfiguration
      storageConfigurationRef: remotePostgresqlStorageConfiguration
      webhooksConfigurationRef: webhooksConfiguration

      metricsScrapingEnabled: false
      migrations:
        enabled: false
      replicas: 1
      autoScaling:
        minReplicaCount: 1
        maxReplicaCount: 1
      extraConfig:
        history_counters_url: http://counters-rpc:5011/counters_history/history.json#
      hosts:
        - webapp-cassandra-next-version.internal.staging.swh.network
      refreshSavecodenowStatus:
        enabled: false
      syncMailmaps:
        enabled: false
      ingress:
        whitelistSourceRangeRef: stagingNetworkRanges
        endpoints:
          default:
            paths:
              - path: /
              - path: /static
                port: 80
            extraWhitelistSourceRange:
              # vpn network
              - 192.168.101.0/24
          authenticated:
            paths:
              - path: /api/1/provenance/
              - path: /api/1/entity/
              - path: /api/1/content/[^/]+/symbol/
            # auth-file with authentication
            authentication: swh-cassandra/web-auth-secrets
            extraWhitelistSourceRange:
              # vpn network
              - 192.168.101.0/24

deposit:
  enabled: false
  migrations:
    enabled: false

graphql:
  deployments:
    cassandra:
      replicas: 1
      hosts:
        - webapp-cassandra-next-version.internal.staging.swh.network

podPriority:
  # This test environment should not impact the real staging environment
  # so we need to use lower priorities than the 'normal' versions
  priorities:
    storages:
      value: -100000
    frontend-rpc:
      value: -10100
    frontend-rpc-workload:
      value: -10200
    high-workload:
      value: -10300
    local-workload:
      value: -10400
    normal-workload:
      value: -10500
    tools:
      value: -10600
    low-workload:
      value: -10700
    background-storage:
      value: -10800
    background-workload:
      value: -10900

schedulerJournalClientConfiguration:
  brokersConfigurationRef: internalSecuredKafkaBrokers
  group_id: swh-scheduler-journal-client

scheduler:
  enabled: true
  schedulerConfigurationRef: remoteSchedulerConfiguration
  celeryConfigurationRef: celeryConfiguration
  sentry:
    enabled: false
  alerts:
    enabled: false
  rpc:
    enabled: true
    backend:
      # check db version with latest code?
      check: true
      # migrate db?
      migrate: false
      # register task types?
      register: true
    ingress:
      enabled: false
  updateMetrics:
    enabled: false
  journalClient:
    enabled: true
    journalConfigurationRef: schedulerJournalClientConfiguration
  extraServices:
    runner:
      enabled: true
    runner-priority:
      enabled: true
    listener:
      enabled: true
      replicas: 1

scrubber:
  enabled: false

toolbox:
  enabled: true
  configs:
    storage:
      storageDbConfigurationRef: postgresqlRWStorageConfiguration
  bulkLoad: null

webhooks:
  enabled: false

listers:
  enabled: true
  storageConfigurationRef: remoteROStorageConfiguration
  schedulerConfigurationRef: remoteSchedulerConfiguration
  celeryConfigurationRef: celeryConfiguration
  deployments:
    nixguix:
      queues:
      - swh.lister.nixguix.tasks.NixGuixListerTask
      autoScaling:
        queueThreshold: 1
        stopWhenNoActivity: false
        minReplicaCount: 1
        maxReplicaCount: 1
      extraConfig:
        # extra extensions to ignore
        extensions_to_ignore:
          - rock

elasticsearchHosts:
  - host: search-es-http
    port: 9200

elasticsearchConfiguration:
  elasticsearchInstancesRef: elasticsearchHosts
  cls: elasticsearch
  indexes:
    origin:
      index: origin-v0.11
      read_alias: origin-read
      write_alias: origin-write

remoteSearchConfiguration:
  cls: remote
  url: http://search-rpc:5010

searchJournalClientConfiguration:
  brokersConfigurationRef: internalSecuredKafkaBrokers
  group_id: swh-search

search:
  enabled: true
  backend:
    initialize: true
  ingress:
    enabled: false
  elasticsearchConfigurationRef: elasticsearchConfiguration
  logLevel: INFO
  autoScaling:
    minReplicaCount: 1
    maxReplicaCount: 1
  gunicorn:
    threads: 4
    workers: 1
    timeout: 60
  # RPC services may have different profiles than the rest so they need their specific
  # setup
  requestedMemory: 512Mi
  requestedCpu: 500m
  journalClients:
    enabled: true
    priorityClassName: normal-workload
    searchConfigurationRef: remoteSearchConfiguration
    storageConfigurationRef: remotePostgresqlStorageConfiguration
    journalConfigurationRef: searchJournalClientConfiguration
    deployments:
      objects:
        journalClientOverrides:
          group_id: swh-search-journal-client-origins
          prefix: swh.journal.objects
          object_types:
            - origin
            - origin_visit_status

      indexed:
        requestedCpu: 10m
        requestedMemory: 50Mi
        journalClientOverrides:
          group_id: swh-search-journal-client-indexed-v0.11
          prefix: swh.journal.indexed
          object_types:
          - origin_intrinsic_metadata
          - origin_extrinsic_metadata

checkerDeposit:
  enabled: false

postgresqlIndexerStorageConfiguration:
  cls: postgresql
  host: next-version-swh-indexer-rw
  port: 5432
  db: swh-indexer
  user: ${POSTGRESQL_IDX_USERNAME}
  pass: ${POSTGRESQL_IDX_PASSWORD}
  secrets:
    POSTGRESQL_IDX_USERNAME:
      secretKeyRef: swh-postgresql-swh-swh-indexer-secret
      secretKeyName: username
    POSTGRESQL_IDX_PASSWORD:
      secretKeyRef: swh-postgresql-swh-swh-indexer-secret
      secretKeyName: password

indexerJournalWriterConfiguration:
  brokersConfigurationRef: readWriteInternalKafkaBrokers
  cls: kafka
  anonymize: true
  client_id: swh-indexer-storage-journal-writer-storage
  prefix: swh.journal.indexed
  producer_config:
    message.max.bytes: 1000000000

indexerStorage:
  enabled: true
  deployments:
    # Deactivate the indexer-storage from swh/values/swh-cassandra.yaml
    rpc:
      enabled: false
    rw:
      backend:
        # When true, initalize the backend, leave it empty to do nothing
        initialize:
          adminSecret: next-version-swh-indexer-superuser
          database: swh-indexer
        # When true, check db & code versions and do not start if they diverge
        check: true
        # When true, migrate or initialize db model
        migrate: true

      replicas: 1
      requestedCpu: 500m
      requestedMemory: 512Mi
      indexerStorageConfigurationRef: postgresqlIndexerStorageConfiguration
      journalWriterConfigurationRef: indexerJournalWriterConfiguration
      gunicorn:
        threads: 1
        workers: 2

remoteIndexerStorageConfiguration:
  cls: remote
  url: http://indexer-storage-rw:5007

indexerJournalClientConfiguration:
  cls: kafka
  brokersConfigurationRef: readWriteInternalKafkaBrokers
  group_id: swh-indexer-journal-client
  prefix: swh.journal.indexed

indexers:
  enabled: true
  storageConfigurationRef: remoteROStorageConfiguration
  schedulerConfigurationRef: remoteSchedulerConfiguration
  indexerStorageConfigurationRef: remoteIndexerStorageConfiguration
  objstorageConfigurationRef: rpcRWObjstoragePathslicingConfiguration
  journalClientConfigurationRef: indexerJournalClientConfiguration
  deployments:
    origin-intrinsic:
      indexer_type: origin_intrinsic_metadata
      journalClientOverrides:
        group_id: swh-indexer-journal-client-origin-intrinsic-metadata
        batch_size: 200
      requestedCpu: 50m
      requestedMemory: 100Mi
      extraConfig:
        tools:
          name: swh-metadata-detector
          version: 0.0.2
          configuration: {}
      autoScaling:
        maxReplicaCount: 1
    extrinsic:
      indexer_type: extrinsic_metadata
      journalClientOverrides:
        group_id: swh-indexer-journal-client-extrinsic-metadata
        prefix: swh.journal.objects
        batch_size: 200
      requestedCpu: 50m
      requestedMemory: 100Mi
      extraConfig:
        tools:
          name: swh-metadata-detector
          version: 0.0.2
          configuration: {}
      autoScaling:
        maxReplicaCount: 1

cassandraChecks:
  enabled: false

alter:
  enabled: false
